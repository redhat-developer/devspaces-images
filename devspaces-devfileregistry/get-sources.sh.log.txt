======= BOOTSTRAP DOCKERFILE =======>
#
# Copyright (c) 2018-2023 Red Hat, Inc.
# This program and the accompanying materials are made
# available under the terms of the Eclipse Public License 2.0
# which is available at https://www.eclipse.org/legal/epl-2.0/
#
# SPDX-License-Identifier: EPL-2.0
#
# Contributors:
#   Red Hat, Inc. - initial API and implementation
#   IBM Corporation - implementation
#

# Builder: check meta.yamls and create index.json
# https://registry.access.redhat.com/ubi8/python-38
FROM registry.access.redhat.com/ubi8/python-38:1-131 as builder
#FROM registry-proxy.engineering.redhat.com/ubi8/python-38:1 as builder
USER 0

ARG BOOTSTRAP=true
ENV BOOTSTRAP=${BOOTSTRAP}
# if not defined or string is null, allow all registries/tags in list_referenced_images
# otherwise restrict to only those space-separated registries/tags; if others found, build will fail
# useful for failing build if quay images in an RC, or wrong devspaces image tag (3.2 in 3.1 build)
ARG ALLOWED_REGISTRIES=""
ENV ALLOWED_REGISTRIES=${ALLOWED_REGISTRIES}
ARG ALLOWED_TAGS=""
ENV ALLOWED_TAGS=${ALLOWED_TAGS}

COPY ./build/dockerfiles/content_sets_rhel8.repo /etc/yum.repos.d/
COPY ./build/dockerfiles/rhel.install.sh /tmp
RUN /tmp/rhel.install.sh && rm -f /tmp/rhel.install.sh

COPY ./build/scripts ./versions.json /build/
COPY ./build/scripts/clone_and_zip.sh /build/build/scripts/
COPY ./VERSION /
COPY ./devfiles /build/devfiles
WORKDIR /build/

RUN ./generate_devworkspace_templates.sh
RUN chmod -R g+rwX /build/resources

# validate devfile content
RUN ./check_referenced_images.sh devfiles --registries "${ALLOWED_REGISTRIES}" --tags "${ALLOWED_TAGS}"
RUN ./check_mandatory_fields.sh devfiles

# Cache projects in DS 
COPY ./build/dockerfiles/rhel.cache_projects.sh /tmp/ 
RUN /tmp/rhel.cache_projects.sh /build/ && rm -rf /tmp/rhel.cache_projects.sh /tmp/resources.tgz 

# don't do swaps, or we end up with missing content if built on s390x or ppc64le worker
# RUN ./swap_yamlfiles.sh devfiles
# RUN ./swap_images.sh devfiles
RUN ./index.sh > /build/devfiles/index.json && \
    ./list_referenced_images.sh devfiles > /build/devfiles/external_images.txt && \
    ./list_referenced_images_by_file.sh devfiles > /build/devfiles/external_images_by_devfile.txt && \
    chmod -R g+rwX /build/devfiles

<======= BOOTSTRAP DOCKERFILE =======
======= START BOOTSTRAP BUILD =======>
STEP 1/23: FROM registry.access.redhat.com/ubi8/python-38:1-131 AS builder
STEP 2/23: USER 0
--> 01067abced62
STEP 3/23: ARG BOOTSTRAP=true
--> b88b51bd25fa
STEP 4/23: ENV BOOTSTRAP=${BOOTSTRAP}
--> 1a971e604878
STEP 5/23: ARG ALLOWED_REGISTRIES=""
--> 1d28b2bbbbf1
STEP 6/23: ENV ALLOWED_REGISTRIES=${ALLOWED_REGISTRIES}
--> bbce6354fcf2
STEP 7/23: ARG ALLOWED_TAGS=""
--> a7420bffd905
STEP 8/23: ENV ALLOWED_TAGS=${ALLOWED_TAGS}
--> 4816c80d8b5e
STEP 9/23: COPY ./build/dockerfiles/content_sets_rhel8.repo /etc/yum.repos.d/
--> 010eb9f7a322
STEP 10/23: COPY ./build/dockerfiles/rhel.install.sh /tmp
--> c53a8ea9a251
STEP 11/23: RUN /tmp/rhel.install.sh && rm -f /tmp/rhel.install.sh

Upgraded:
  dnf-4.7.0-19.el8.noarch                dnf-data-4.7.0-19.el8.noarch          
  findutils-1:4.6.0-21.el8.x86_64        python3-dnf-4.7.0-19.el8.noarch       
  yum-4.7.0-19.el8.noarch               
Installed:
  containers-common-2:1-70.module+el8.9.0+20326+387084d0.x86_64                 
  criu-3.18-4.module+el8.9.0+20326+387084d0.x86_64                              
  fuse-common-3.3.0-17.el8.x86_64                                               
  fuse-overlayfs-1.12-1.module+el8.9.0+20326+387084d0.x86_64                    
  fuse3-3.3.0-17.el8.x86_64                                                     
  fuse3-libs-3.3.0-17.el8.x86_64                                                
  jq-1.6-7.el8.x86_64                                                           
  kmod-25-19.el8.x86_64                                                         
  libnet-1.1.6-15.el8.x86_64                                                    
  libslirp-4.4.0-1.module+el8.9.0+20326+387084d0.x86_64                         
  mpdecimal-2.5.1-3.el8.x86_64                                                  
  oniguruma-6.8.2-2.el8.x86_64                                                  
  protobuf-c-1.3.0-8.el8.x86_64                                                 
  python3.11-3.11.5-1.el8_9.x86_64                                              
  python3.11-devel-3.11.5-1.el8_9.x86_64                                        
  python3.11-libs-3.11.5-1.el8_9.x86_64                                         
  python3.11-pip-22.3.1-4.el8.noarch                                            
  python3.11-pip-wheel-22.3.1-4.el8.noarch                                      
  python3.11-setuptools-65.5.1-2.el8.noarch                                     
  python3.11-setuptools-wheel-65.5.1-2.el8.noarch                               
  runc-1:1.1.9-1.module+el8.9.0+20326+387084d0.x86_64                           
  skopeo-2:1.13.3-1.module+el8.9.0+20326+387084d0.x86_64                        
  slirp4netns-1.2.1-1.module+el8.9.0+20326+387084d0.x86_64                      

Collecting yq
  Downloading yq-3.2.3-py3-none-any.whl (17 kB)
Collecting argcomplete
  Downloading argcomplete-3.2.2-py3-none-any.whl (42 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.3/42.3 kB 5.7 MB/s eta 0:00:00
Requirement already satisfied: pip in /usr/lib/python3.11/site-packages (22.3.1)
Collecting pip
  Downloading pip-24.0-py3-none-any.whl (2.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 60.1 MB/s eta 0:00:00
Collecting PyYAML>=5.3.1
  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 757.7/757.7 kB 381.8 MB/s eta 0:00:00
Collecting xmltodict>=0.11.0
  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)
Collecting tomlkit>=0.11.6
  Downloading tomlkit-0.12.3-py3-none-any.whl (37 kB)
Installing collected packages: xmltodict, tomlkit, PyYAML, pip, argcomplete, yq
Successfully installed PyYAML-6.0.1 argcomplete-3.2.2 pip-24.0 tomlkit-0.12.3 xmltodict-0.13.0 yq-3.2.3
python: Python 3.8.16
yq: yq 3.2.3
jq: jq-1.6
--> cc7cc464a889
STEP 12/23: COPY ./build/scripts ./versions.json /build/
--> 5e8d58aa2a35
STEP 13/23: COPY ./build/scripts/clone_and_zip.sh /build/build/scripts/
--> eef27a48ab9d
STEP 14/23: COPY ./VERSION /
--> 0af5496e4db7
STEP 15/23: COPY ./devfiles /build/devfiles
--> 73d517e69b1a
STEP 16/23: WORKDIR /build/
--> 3e4b50f94399
STEP 17/23: RUN ./generate_devworkspace_templates.sh
+ @eclipse-che/che-devworkspace-generator@0.0.1-99986b8
added 31 packages from 84 contributors and audited 31 packages in 5.753s

1 package is looking for funding
  run `npm fund` for details

found 1 moderate severity vulnerability
  run `npm audit fix` to fix them, or `npm audit` for details
DevWorkspace che-code-ansible-demo was generated.
DevWorkspace che-code-ansible-demo was generated.
DevWorkspace che-idea-ansible-demo was generated.
DevWorkspace che-code-java-lombok was generated.
DevWorkspace che-code-java-lombok was generated.
DevWorkspace che-idea-java-lombok was generated.
DevWorkspace che-code-quarkus-quickstart was generated.
DevWorkspace che-code-quarkus-quickstart was generated.
DevWorkspace che-idea-quarkus-quickstart was generated.
DevWorkspace che-code-nodejs-mongodb was generated.
DevWorkspace che-code-nodejs-mongodb was generated.
DevWorkspace che-idea-nodejs-mongodb was generated.
DevWorkspace che-code-nodejs-web-app was generated.
DevWorkspace che-code-nodejs-web-app was generated.
DevWorkspace che-idea-nodejs-web-app was generated.
DevWorkspace che-code-python-hello-world was generated.
DevWorkspace che-code-python-hello-world was generated.
DevWorkspace che-idea-python-hello-world was generated.
DevWorkspace che-code-cpp was generated.
DevWorkspace che-code-cpp was generated.
DevWorkspace che-idea-cpp was generated.
DevWorkspace che-code-dotnet was generated.
DevWorkspace che-code-dotnet was generated.
DevWorkspace che-idea-dotnet was generated.
DevWorkspace che-code-golang was generated.
DevWorkspace che-code-golang was generated.
DevWorkspace che-idea-golang was generated.
DevWorkspace che-code-php-hello-world was generated.
DevWorkspace che-code-php-hello-world was generated.
DevWorkspace che-idea-php-hello-world was generated.
--> 472fc53603b7
STEP 18/23: RUN chmod -R g+rwX /build/resources
--> 36ed976b7a70
STEP 19/23: RUN ./check_referenced_images.sh devfiles --registries "${ALLOWED_REGISTRIES}" --tags "${ALLOWED_TAGS}"
 = quay.io/devspaces/ansible-creator-ee@sha256:3128cce4c1f2c1600db7750ad8b1b0cc655fb59c621d982c863c24696c4bd68c PASS
 + registry.redhat.io/devspaces/code-rhel8:3.13 PASS - 3.13 allowed
 + registry.redhat.io/devspaces/idea-rhel8:3.13 PASS - 3.13 allowed
 + registry.redhat.io/devspaces/udi-rhel8:3.13 PASS - 3.13 allowed
 = registry.redhat.io/rhscl/mongodb-36-rhel7:1-50 PASS
--> 0484aed031cb
STEP 20/23: RUN ./check_mandatory_fields.sh devfiles
Checking devfile 'devfiles/TP__cpp__c-plus-plus/meta.yaml'
Checking devfile 'devfiles/TP__dotnet__dotnet-web-simple/meta.yaml'
Checking devfile 'devfiles/TP__go__golang-health-check/meta.yaml'
Checking devfile 'devfiles/TP__php__php-hello-world/meta.yaml'
Checking devfile 'devfiles/ansible__ansible-demo/meta.yaml'
Checking devfile 'devfiles/java-maven-lombok__lombok-project-sample/meta.yaml'
Checking devfile 'devfiles/java-maven-quarkus__quarkus-quickstarts/meta.yaml'
Checking devfile 'devfiles/nodejs__nodejs-mongodb-sample/meta.yaml'
Checking devfile 'devfiles/nodejs__web-nodejs-sample/meta.yaml'
Checking devfile 'devfiles/python__python-hello-world/meta.yaml'
--> 3fbb78fd3ed3
STEP 21/23: COPY ./build/dockerfiles/rhel.cache_projects.sh /tmp/ 
--> ad4528fb1fb7
STEP 22/23: RUN /tmp/rhel.cache_projects.sh /build/ && rm -rf /tmp/rhel.cache_projects.sh /tmp/resources.tgz 
--> 3bfbaaf3a52b
STEP 23/23: RUN ./index.sh > /build/devfiles/index.json &&     ./list_referenced_images.sh devfiles > /build/devfiles/external_images.txt &&     ./list_referenced_images_by_file.sh devfiles > /build/devfiles/external_images_by_devfile.txt &&     chmod -R g+rwX /build/devfiles
COMMIT devfileregistry:tmp
--> 354b4d424f55
Successfully tagged localhost/devfileregistry:tmp
354b4d424f55b00eef526ef7d67917d585e5c772bad7749f147c58ece81d1cd5
<======= END BOOTSTRAP BUILD =======
Downloading root-local.tgz
Downloading resources.tgz
DIFF START *****
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/__init__.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/__init__.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/__init__.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/__init__.py	2024-02-03 17:39:20.021082493 -0500
@@ -1,6 +1,6 @@
 from typing import List, Optional
 
-__version__ = "23.3.2"
+__version__ = "24.0"
 
 
 def main(args: Optional[List[str]] = None) -> int:
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/cli/cmdoptions.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/cli/cmdoptions.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/cli/cmdoptions.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/cli/cmdoptions.py	2024-02-03 17:39:20.029082493 -0500
@@ -582,10 +582,7 @@
     """
     version_info, error_msg = _convert_python_version(value)
     if error_msg is not None:
-        msg = "invalid --python-version value: {!r}: {}".format(
-            value,
-            error_msg,
-        )
+        msg = f"invalid --python-version value: {value!r}: {error_msg}"
         raise_option_error(parser, option=option, msg=msg)
 
     parser.values.python_version = version_info
@@ -921,9 +918,9 @@
         algo, digest = value.split(":", 1)
     except ValueError:
         parser.error(
-            "Arguments to {} must be a hash name "
+            f"Arguments to {opt_str} must be a hash name "
             "followed by a value, like --hash=sha256:"
-            "abcde...".format(opt_str)
+            "abcde..."
         )
     if algo not in STRONG_HASHES:
         parser.error(
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/cli/parser.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/cli/parser.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/cli/parser.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/cli/parser.py	2024-02-03 17:39:20.030082493 -0500
@@ -229,9 +229,9 @@
                     val = strtobool(val)
                 except ValueError:
                     self.error(
-                        "{} is not a valid value for {} option, "
+                        f"{val} is not a valid value for {key} option, "
                         "please specify a boolean value like yes/no, "
-                        "true/false or 1/0 instead.".format(val, key)
+                        "true/false or 1/0 instead."
                     )
             elif option.action == "count":
                 with suppress(ValueError):
@@ -240,10 +240,10 @@
                     val = int(val)
                 if not isinstance(val, int) or val < 0:
                     self.error(
-                        "{} is not a valid value for {} option, "
+                        f"{val} is not a valid value for {key} option, "
                         "please instead specify either a non-negative integer "
                         "or a boolean value like yes/no or false/true "
-                        "which is equivalent to 1/0.".format(val, key)
+                        "which is equivalent to 1/0."
                     )
             elif option.action == "append":
                 val = val.split()
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/commands/cache.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/commands/cache.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/commands/cache.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/commands/cache.py	2024-02-03 17:39:20.033082493 -0500
@@ -175,7 +175,7 @@
             files += self._find_http_files(options)
         else:
             # Add the pattern to the log message
-            no_matching_msg += ' for pattern "{}"'.format(args[0])
+            no_matching_msg += f' for pattern "{args[0]}"'
 
         if not files:
             logger.warning(no_matching_msg)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/commands/configuration.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/commands/configuration.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/commands/configuration.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/commands/configuration.py	2024-02-03 17:39:20.033082493 -0500
@@ -242,17 +242,15 @@
                 e.filename = editor
             raise
         except subprocess.CalledProcessError as e:
-            raise PipError(
-                "Editor Subprocess exited with exit code {}".format(e.returncode)
-            )
+            raise PipError(f"Editor Subprocess exited with exit code {e.returncode}")
 
     def _get_n_args(self, args: List[str], example: str, n: int) -> Any:
         """Helper to make sure the command got the right number of arguments"""
         if len(args) != n:
             msg = (
-                "Got unexpected number of arguments, expected {}. "
-                '(example: "{} config {}")'
-            ).format(n, get_prog(), example)
+                f"Got unexpected number of arguments, expected {n}. "
+                f'(example: "{get_prog()} config {example}")'
+            )
             raise PipError(msg)
 
         if n == 1:
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/commands/debug.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/commands/debug.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/commands/debug.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/commands/debug.py	2024-02-03 17:39:20.033082493 -0500
@@ -95,7 +95,7 @@
         elif parse_version(actual_version) != parse_version(expected_version):
             extra_message = (
                 " (CONFLICT: vendor.txt suggests version should"
-                " be {})".format(expected_version)
+                f" be {expected_version})"
             )
         logger.info("%s==%s%s", module_name, actual_version, extra_message)
 
@@ -120,7 +120,7 @@
     if formatted_target:
         suffix = f" (target: {formatted_target})"
 
-    msg = "Compatible tags: {}{}".format(len(tags), suffix)
+    msg = f"Compatible tags: {len(tags)}{suffix}"
     logger.info(msg)
 
     if options.verbose < 1 and len(tags) > tag_limit:
@@ -134,9 +134,7 @@
             logger.info(str(tag))
 
         if tags_limited:
-            msg = (
-                "...\n[First {tag_limit} tags shown. Pass --verbose to show all.]"
-            ).format(tag_limit=tag_limit)
+            msg = f"...\n[First {tag_limit} tags shown. Pass --verbose to show all.]"
             logger.info(msg)
 
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/commands/index.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/commands/index.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/commands/index.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/commands/index.py	2024-02-03 17:39:20.033082493 -0500
@@ -128,12 +128,12 @@
 
             if not versions:
                 raise DistributionNotFound(
-                    "No matching distribution found for {}".format(query)
+                    f"No matching distribution found for {query}"
                 )
 
             formatted_versions = [str(ver) for ver in sorted(versions, reverse=True)]
             latest = formatted_versions[0]
 
-        write_output("{} ({})".format(query, latest))
+        write_output(f"{query} ({latest})")
         write_output("Available versions: {}".format(", ".join(formatted_versions)))
         print_dist_installation_info(query, latest)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/commands/install.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/commands/install.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/commands/install.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/commands/install.py	2024-02-03 17:39:20.033082493 -0500
@@ -607,12 +607,8 @@
             version = package_set[project_name][0]
             for dependency in missing[project_name]:
                 message = (
-                    "{name} {version} requires {requirement}, "
+                    f"{project_name} {version} requires {dependency[1]}, "
                     "which is not installed."
-                ).format(
-                    name=project_name,
-                    version=version,
-                    requirement=dependency[1],
                 )
                 parts.append(message)
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/configuration.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/configuration.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/configuration.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/configuration.py	2024-02-03 17:39:20.026082493 -0500
@@ -59,8 +59,8 @@
     if "." not in name:
         error_message = (
             "Key does not contain dot separated section and key. "
-            "Perhaps you wanted to use 'global.{}' instead?"
-        ).format(name)
+            f"Perhaps you wanted to use 'global.{name}' instead?"
+        )
         raise ConfigurationError(error_message)
     return name.split(".", 1)
 
@@ -327,33 +327,35 @@
     def iter_config_files(self) -> Iterable[Tuple[Kind, List[str]]]:
         """Yields variant and configuration files associated with it.
 
-        This should be treated like items of a dictionary.
+        This should be treated like items of a dictionary. The order
+        here doesn't affect what gets overridden. That is controlled
+        by OVERRIDE_ORDER. However this does control the order they are
+        displayed to the user. It's probably most ergononmic to display
+        things in the same order as OVERRIDE_ORDER
         """
         # SMELL: Move the conditions out of this function
 
-        # environment variables have the lowest priority
-        config_file = os.environ.get("PIP_CONFIG_FILE", None)
-        if config_file is not None:
-            yield kinds.ENV, [config_file]
-        else:
-            yield kinds.ENV, []
-
+        env_config_file = os.environ.get("PIP_CONFIG_FILE", None)
         config_files = get_configuration_files()
 
-        # at the base we have any global configuration
         yield kinds.GLOBAL, config_files[kinds.GLOBAL]
 
-        # per-user configuration next
+        # per-user config is not loaded when env_config_file exists
         should_load_user_config = not self.isolated and not (
-            config_file and os.path.exists(config_file)
+            env_config_file and os.path.exists(env_config_file)
         )
         if should_load_user_config:
             # The legacy config file is overridden by the new config file
             yield kinds.USER, config_files[kinds.USER]
 
-        # finally virtualenv configuration first trumping others
+        # virtualenv config
         yield kinds.SITE, config_files[kinds.SITE]
 
+        if env_config_file is not None:
+            yield kinds.ENV, [env_config_file]
+        else:
+            yield kinds.ENV, []
+
     def get_values_in_config(self, variant: Kind) -> Dict[str, Any]:
         """Get values present in a config file"""
         return self._config[variant]
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/exceptions.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/exceptions.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/exceptions.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/exceptions.py	2024-02-03 17:39:20.026082493 -0500
@@ -247,10 +247,7 @@
     def __str__(self) -> str:
         # Use `dist` in the error message because its stringification
         # includes more information, like the version and location.
-        return "None {} metadata found for distribution: {}".format(
-            self.metadata_name,
-            self.dist,
-        )
+        return f"None {self.metadata_name} metadata found for distribution: {self.dist}"
 
 
 class UserInstallationInvalid(InstallationError):
@@ -594,7 +591,7 @@
         self.gots = gots
 
     def body(self) -> str:
-        return "    {}:\n{}".format(self._requirement_name(), self._hash_comparison())
+        return f"    {self._requirement_name()}:\n{self._hash_comparison()}"
 
     def _hash_comparison(self) -> str:
         """
@@ -616,11 +613,9 @@
         lines: List[str] = []
         for hash_name, expecteds in self.allowed.items():
             prefix = hash_then_or(hash_name)
-            lines.extend(
-                ("        Expected {} {}".format(next(prefix), e)) for e in expecteds
-            )
+            lines.extend((f"        Expected {next(prefix)} {e}") for e in expecteds)
             lines.append(
-                "             Got        {}\n".format(self.gots[hash_name].hexdigest())
+                f"             Got        {self.gots[hash_name].hexdigest()}\n"
             )
         return "\n".join(lines)
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/index/collector.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/index/collector.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/index/collector.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/index/collector.py	2024-02-03 17:39:20.035082493 -0500
@@ -473,6 +473,7 @@
                 page_validator=self.session.is_secure_origin,
                 expand_dir=False,
                 cache_link_parsing=False,
+                project_name=project_name,
             )
             for loc in self.search_scope.get_index_urls_locations(project_name)
         ).values()
@@ -483,6 +484,7 @@
                 page_validator=self.session.is_secure_origin,
                 expand_dir=True,
                 cache_link_parsing=True,
+                project_name=project_name,
             )
             for loc in self.find_links
         ).values()
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/index/package_finder.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/index/package_finder.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/index/package_finder.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/index/package_finder.py	2024-02-03 17:39:20.035082493 -0500
@@ -533,8 +533,8 @@
                 )
             except ValueError:
                 raise UnsupportedWheel(
-                    "{} is not a supported wheel for this platform. It "
-                    "can't be sorted.".format(wheel.filename)
+                    f"{wheel.filename} is not a supported wheel for this platform. It "
+                    "can't be sorted."
                 )
             if self._prefer_binary:
                 binary_preference = 1
@@ -939,9 +939,7 @@
                 _format_versions(best_candidate_result.iter_all()),
             )
 
-            raise DistributionNotFound(
-                "No matching distribution found for {}".format(req)
-            )
+            raise DistributionNotFound(f"No matching distribution found for {req}")
 
         def _should_install_candidate(
             candidate: Optional[InstallationCandidate],
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/index/sources.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/index/sources.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/index/sources.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/index/sources.py	2024-02-03 17:39:20.035082493 -0500
@@ -1,8 +1,17 @@
 import logging
 import mimetypes
 import os
-import pathlib
-from typing import Callable, Iterable, Optional, Tuple
+from collections import defaultdict
+from typing import Callable, Dict, Iterable, List, Optional, Tuple
+
+from pip._vendor.packaging.utils import (
+    InvalidSdistFilename,
+    InvalidVersion,
+    InvalidWheelFilename,
+    canonicalize_name,
+    parse_sdist_filename,
+    parse_wheel_filename,
+)
 
 from pip._internal.models.candidate import InstallationCandidate
 from pip._internal.models.link import Link
@@ -36,6 +45,53 @@
     return mimetypes.guess_type(file_url, strict=False)[0] == "text/html"
 
 
+class _FlatDirectoryToUrls:
+    """Scans directory and caches results"""
+
+    def __init__(self, path: str) -> None:
+        self._path = path
+        self._page_candidates: List[str] = []
+        self._project_name_to_urls: Dict[str, List[str]] = defaultdict(list)
+        self._scanned_directory = False
+
+    def _scan_directory(self) -> None:
+        """Scans directory once and populates both page_candidates
+        and project_name_to_urls at the same time
+        """
+        for entry in os.scandir(self._path):
+            url = path_to_url(entry.path)
+            if _is_html_file(url):
+                self._page_candidates.append(url)
+                continue
+
+            # File must have a valid wheel or sdist name,
+            # otherwise not worth considering as a package
+            try:
+                project_filename = parse_wheel_filename(entry.name)[0]
+            except (InvalidWheelFilename, InvalidVersion):
+                try:
+                    project_filename = parse_sdist_filename(entry.name)[0]
+                except (InvalidSdistFilename, InvalidVersion):
+                    continue
+
+            self._project_name_to_urls[project_filename].append(url)
+        self._scanned_directory = True
+
+    @property
+    def page_candidates(self) -> List[str]:
+        if not self._scanned_directory:
+            self._scan_directory()
+
+        return self._page_candidates
+
+    @property
+    def project_name_to_urls(self) -> Dict[str, List[str]]:
+        if not self._scanned_directory:
+            self._scan_directory()
+
+        return self._project_name_to_urls
+
+
 class _FlatDirectorySource(LinkSource):
     """Link source specified by ``--find-links=<path-to-dir>``.
 
@@ -45,30 +101,34 @@
     * ``file_candidates``: Archives in the directory.
     """
 
+    _paths_to_urls: Dict[str, _FlatDirectoryToUrls] = {}
+
     def __init__(
         self,
         candidates_from_page: CandidatesFromPage,
         path: str,
+        project_name: str,
     ) -> None:
         self._candidates_from_page = candidates_from_page
-        self._path = pathlib.Path(os.path.realpath(path))
+        self._project_name = canonicalize_name(project_name)
+
+        # Get existing instance of _FlatDirectoryToUrls if it exists
+        if path in self._paths_to_urls:
+            self._path_to_urls = self._paths_to_urls[path]
+        else:
+            self._path_to_urls = _FlatDirectoryToUrls(path=path)
+            self._paths_to_urls[path] = self._path_to_urls
 
     @property
     def link(self) -> Optional[Link]:
         return None
 
     def page_candidates(self) -> FoundCandidates:
-        for path in self._path.iterdir():
-            url = path_to_url(str(path))
-            if not _is_html_file(url):
-                continue
+        for url in self._path_to_urls.page_candidates:
             yield from self._candidates_from_page(Link(url))
 
     def file_links(self) -> FoundLinks:
-        for path in self._path.iterdir():
-            url = path_to_url(str(path))
-            if _is_html_file(url):
-                continue
+        for url in self._path_to_urls.project_name_to_urls[self._project_name]:
             yield Link(url)
 
 
@@ -170,6 +230,7 @@
     page_validator: PageValidator,
     expand_dir: bool,
     cache_link_parsing: bool,
+    project_name: str,
 ) -> Tuple[Optional[str], Optional[LinkSource]]:
     path: Optional[str] = None
     url: Optional[str] = None
@@ -203,6 +264,7 @@
             source = _FlatDirectorySource(
                 candidates_from_page=candidates_from_page,
                 path=path,
+                project_name=project_name,
             )
         else:
             source = _IndexDirectorySource(
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/locations/_distutils.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/locations/_distutils.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/locations/_distutils.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/locations/_distutils.py	2024-02-03 17:39:20.022082493 -0500
@@ -56,8 +56,7 @@
         try:
             d.parse_config_files()
         except UnicodeDecodeError:
-            # Typeshed does not include find_config_files() for some reason.
-            paths = d.find_config_files()  # type: ignore
+            paths = d.find_config_files()
             logger.warning(
                 "Ignore distutils configs in %s due to encoding errors.",
                 ", ".join(os.path.basename(p) for p in paths),
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/metadata/_json.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/metadata/_json.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/metadata/_json.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/metadata/_json.py	2024-02-03 17:39:20.024082493 -0500
@@ -64,10 +64,10 @@
         key = json_name(field)
         if multi:
             value: Union[str, List[str]] = [
-                sanitise_header(v) for v in msg.get_all(field)
+                sanitise_header(v) for v in msg.get_all(field)  # type: ignore
             ]
         else:
-            value = sanitise_header(msg.get(field))
+            value = sanitise_header(msg.get(field))  # type: ignore
             if key == "keywords":
                 # Accept both comma-separated and space-separated
                 # forms, for better compatibility with old data.
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/models/candidate.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/models/candidate.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/models/candidate.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/models/candidate.py	2024-02-03 17:39:20.024082493 -0500
@@ -27,8 +27,4 @@
         )
 
     def __str__(self) -> str:
-        return "{!r} candidate (version {} at {})".format(
-            self.name,
-            self.version,
-            self.link,
-        )
+        return f"{self.name!r} candidate (version {self.version} at {self.link})"
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/models/direct_url.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/models/direct_url.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/models/direct_url.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/models/direct_url.py	2024-02-03 17:39:20.024082493 -0500
@@ -31,9 +31,7 @@
     value = d[key]
     if not isinstance(value, expected_type):
         raise DirectUrlValidationError(
-            "{!r} has unexpected type for {} (expected {})".format(
-                value, key, expected_type
-            )
+            f"{value!r} has unexpected type for {key} (expected {expected_type})"
         )
     return value
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/models/format_control.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/models/format_control.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/models/format_control.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/models/format_control.py	2024-02-03 17:39:20.025082493 -0500
@@ -33,9 +33,7 @@
         return all(getattr(self, k) == getattr(other, k) for k in self.__slots__)
 
     def __repr__(self) -> str:
-        return "{}({}, {})".format(
-            self.__class__.__name__, self.no_binary, self.only_binary
-        )
+        return f"{self.__class__.__name__}({self.no_binary}, {self.only_binary})"
 
     @staticmethod
     def handle_mutual_excludes(value: str, target: Set[str], other: Set[str]) -> None:
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/models/link.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/models/link.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/models/link.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/models/link.py	2024-02-03 17:39:20.025082493 -0500
@@ -368,9 +368,7 @@
         else:
             rp = ""
         if self.comes_from:
-            return "{} (from {}){}".format(
-                redact_auth_from_url(self._url), self.comes_from, rp
-            )
+            return f"{redact_auth_from_url(self._url)} (from {self.comes_from}){rp}"
         else:
             return redact_auth_from_url(str(self._url))
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/network/download.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/network/download.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/network/download.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/network/download.py	2024-02-03 17:39:20.029082493 -0500
@@ -42,7 +42,7 @@
     logged_url = redact_auth_from_url(url)
 
     if total_length:
-        logged_url = "{} ({})".format(logged_url, format_size(total_length))
+        logged_url = f"{logged_url} ({format_size(total_length)})"
 
     if is_from_cache(resp):
         logger.info("Using cached %s", logged_url)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/network/session.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/network/session.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/network/session.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/network/session.py	2024-02-03 17:39:20.029082493 -0500
@@ -355,8 +355,9 @@
             # is typically considered a transient error so we'll go ahead and
             # retry it.
             # A 500 may indicate transient error in Amazon S3
+            # A 502 may be a transient error from a CDN like CloudFlare or CloudFront
             # A 520 or 527 - may indicate transient error in CloudFlare
-            status_forcelist=[500, 503, 520, 527],
+            status_forcelist=[500, 502, 503, 520, 527],
             # Add a small amount of back off between failed requests in
             # order to prevent hammering the service.
             backoff_factor=0.25,
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/network/xmlrpc.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/network/xmlrpc.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/network/xmlrpc.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/network/xmlrpc.py	2024-02-03 17:39:20.029082493 -0500
@@ -13,6 +13,8 @@
 if TYPE_CHECKING:
     from xmlrpc.client import _HostType, _Marshallable
 
+    from _typeshed import SizedBuffer
+
 logger = logging.getLogger(__name__)
 
 
@@ -33,7 +35,7 @@
         self,
         host: "_HostType",
         handler: str,
-        request_body: bytes,
+        request_body: "SizedBuffer",
         verbose: bool = False,
     ) -> Tuple["_Marshallable", ...]:
         assert isinstance(host, str)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/operations/check.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/operations/check.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/operations/check.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/operations/check.py	2024-02-03 17:39:20.031082493 -0500
@@ -168,7 +168,7 @@
                     f"release a version with a conforming version number"
                 ),
                 issue=12063,
-                gone_in="24.0",
+                gone_in="24.1",
             )
         for dep in package_details.dependencies:
             if any(isinstance(spec, LegacySpecifier) for spec in dep.specifier):
@@ -183,5 +183,5 @@
                         f"release a version with a conforming dependency specifiers"
                     ),
                     issue=12063,
-                    gone_in="24.0",
+                    gone_in="24.1",
                 )
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/operations/install/wheel.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/operations/install/wheel.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/operations/install/wheel.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/operations/install/wheel.py	2024-02-03 17:39:20.032082493 -0500
@@ -164,16 +164,14 @@
     for parent_dir, dir_scripts in warn_for.items():
         sorted_scripts: List[str] = sorted(dir_scripts)
         if len(sorted_scripts) == 1:
-            start_text = "script {} is".format(sorted_scripts[0])
+            start_text = f"script {sorted_scripts[0]} is"
         else:
             start_text = "scripts {} are".format(
                 ", ".join(sorted_scripts[:-1]) + " and " + sorted_scripts[-1]
             )
 
         msg_lines.append(
-            "The {} installed in '{}' which is not on PATH.".format(
-                start_text, parent_dir
-            )
+            f"The {start_text} installed in '{parent_dir}' which is not on PATH."
         )
 
     last_line_fmt = (
@@ -321,9 +319,7 @@
             scripts_to_generate.append("pip = " + pip_script)
 
         if os.environ.get("ENSUREPIP_OPTIONS", "") != "altinstall":
-            scripts_to_generate.append(
-                "pip{} = {}".format(sys.version_info[0], pip_script)
-            )
+            scripts_to_generate.append(f"pip{sys.version_info[0]} = {pip_script}")
 
         scripts_to_generate.append(f"pip{get_major_minor_version()} = {pip_script}")
         # Delete any other versioned pip entry points
@@ -336,9 +332,7 @@
             scripts_to_generate.append("easy_install = " + easy_install_script)
 
         scripts_to_generate.append(
-            "easy_install-{} = {}".format(
-                get_major_minor_version(), easy_install_script
-            )
+            f"easy_install-{get_major_minor_version()} = {easy_install_script}"
         )
         # Delete any other versioned easy_install entry points
         easy_install_ep = [
@@ -408,10 +402,10 @@
 class MissingCallableSuffix(InstallationError):
     def __init__(self, entry_point: str) -> None:
         super().__init__(
-            "Invalid script entry point: {} - A callable "
+            f"Invalid script entry point: {entry_point} - A callable "
             "suffix is required. Cf https://packaging.python.org/"
             "specifications/entry-points/#use-for-scripts for more "
-            "information.".format(entry_point)
+            "information."
         )
 
 
@@ -712,7 +706,7 @@
     try:
         yield
     except InstallationError as e:
-        message = "For req: {}. {}".format(req_description, e.args[0])
+        message = f"For req: {req_description}. {e.args[0]}"
         raise InstallationError(message) from e
 
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/operations/prepare.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/operations/prepare.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/operations/prepare.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/operations/prepare.py	2024-02-03 17:39:20.031082493 -0500
@@ -603,8 +603,8 @@
                 )
             except NetworkConnectionError as exc:
                 raise InstallationError(
-                    "Could not install requirement {} because of HTTP "
-                    "error {} for URL {}".format(req, exc, link)
+                    f"Could not install requirement {req} because of HTTP "
+                    f"error {exc} for URL {link}"
                 )
         else:
             file_path = self._downloaded[link.url]
@@ -684,9 +684,9 @@
         with indent_log():
             if self.require_hashes:
                 raise InstallationError(
-                    "The editable requirement {} cannot be installed when "
+                    f"The editable requirement {req} cannot be installed when "
                     "requiring hashes, because there is no single file to "
-                    "hash.".format(req)
+                    "hash."
                 )
             req.ensure_has_source_dir(self.src_dir)
             req.update_editable()
@@ -714,7 +714,7 @@
         assert req.satisfied_by, "req should have been satisfied but isn't"
         assert skip_reason is not None, (
             "did not get skip reason skipped but req.satisfied_by "
-            "is set to {}".format(req.satisfied_by)
+            f"is set to {req.satisfied_by}"
         )
         logger.info(
             "Requirement %s: %s (%s)", skip_reason, req, req.satisfied_by.version
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/pyproject.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/pyproject.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/pyproject.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/pyproject.py	2024-02-03 17:39:20.026082493 -0500
@@ -123,7 +123,7 @@
         # a version of setuptools that supports that backend.
 
         build_system = {
-            "requires": ["setuptools>=40.8.0", "wheel"],
+            "requires": ["setuptools>=40.8.0"],
             "build-backend": "setuptools.build_meta:__legacy__",
         }
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/req/constructors.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/req/constructors.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/req/constructors.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/req/constructors.py	2024-02-03 17:39:20.036082493 -0500
@@ -462,7 +462,7 @@
         raise InstallationError(
             "Packages installed from PyPI cannot depend on packages "
             "which are not also hosted on PyPI.\n"
-            "{} depends on {} ".format(comes_from.name, req)
+            f"{comes_from.name} depends on {req} "
         )
 
     return InstallRequirement(
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/req/req_file.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/req/req_file.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/req/req_file.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/req/req_file.py	2024-02-03 17:39:20.036082493 -0500
@@ -75,8 +75,16 @@
     cmdoptions.config_settings,
 ]
 
+SUPPORTED_OPTIONS_EDITABLE_REQ: List[Callable[..., optparse.Option]] = [
+    cmdoptions.config_settings,
+]
+
+
 # the 'dest' string values
 SUPPORTED_OPTIONS_REQ_DEST = [str(o().dest) for o in SUPPORTED_OPTIONS_REQ]
+SUPPORTED_OPTIONS_EDITABLE_REQ_DEST = [
+    str(o().dest) for o in SUPPORTED_OPTIONS_EDITABLE_REQ
+]
 
 logger = logging.getLogger(__name__)
 
@@ -178,31 +186,25 @@
 
     assert line.is_requirement
 
+    # get the options that apply to requirements
     if line.is_editable:
-        # For editable requirements, we don't support per-requirement
-        # options, so just return the parsed requirement.
-        return ParsedRequirement(
-            requirement=line.requirement,
-            is_editable=line.is_editable,
-            comes_from=line_comes_from,
-            constraint=line.constraint,
-        )
+        supported_dest = SUPPORTED_OPTIONS_EDITABLE_REQ_DEST
     else:
-        # get the options that apply to requirements
-        req_options = {}
-        for dest in SUPPORTED_OPTIONS_REQ_DEST:
-            if dest in line.opts.__dict__ and line.opts.__dict__[dest]:
-                req_options[dest] = line.opts.__dict__[dest]
-
-        line_source = f"line {line.lineno} of {line.filename}"
-        return ParsedRequirement(
-            requirement=line.requirement,
-            is_editable=line.is_editable,
-            comes_from=line_comes_from,
-            constraint=line.constraint,
-            options=req_options,
-            line_source=line_source,
-        )
+        supported_dest = SUPPORTED_OPTIONS_REQ_DEST
+    req_options = {}
+    for dest in supported_dest:
+        if dest in line.opts.__dict__ and line.opts.__dict__[dest]:
+            req_options[dest] = line.opts.__dict__[dest]
+
+    line_source = f"line {line.lineno} of {line.filename}"
+    return ParsedRequirement(
+        requirement=line.requirement,
+        is_editable=line.is_editable,
+        comes_from=line_comes_from,
+        constraint=line.constraint,
+        options=req_options,
+        line_source=line_source,
+    )
 
 
 def handle_option_line(
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/req/req_install.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/req/req_install.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/req/req_install.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/req/req_install.py	2024-02-03 17:39:20.036082493 -0500
@@ -181,6 +181,16 @@
         # but after loading this flag should be treated as read only.
         self.use_pep517 = use_pep517
 
+        # If config settings are provided, enforce PEP 517.
+        if self.config_settings:
+            if self.use_pep517 is False:
+                logger.warning(
+                    "--no-use-pep517 ignored for %s "
+                    "because --config-settings are specified.",
+                    self,
+                )
+            self.use_pep517 = True
+
         # This requirement needs more preparation before it can be built
         self.needs_more_preparation = False
 
@@ -191,7 +201,7 @@
         if self.req:
             s = redact_auth_from_requirement(self.req)
             if self.link:
-                s += " from {}".format(redact_auth_from_url(self.link.url))
+                s += f" from {redact_auth_from_url(self.link.url)}"
         elif self.link:
             s = redact_auth_from_url(self.link.url)
         else:
@@ -221,7 +231,7 @@
         attributes = vars(self)
         names = sorted(attributes)
 
-        state = ("{}={!r}".format(attr, attributes[attr]) for attr in sorted(names))
+        state = (f"{attr}={attributes[attr]!r}" for attr in sorted(names))
         return "<{name} object: {{{state}}}>".format(
             name=self.__class__.__name__,
             state=", ".join(state),
@@ -508,15 +518,7 @@
         )
 
         if pyproject_toml_data is None:
-            if self.config_settings:
-                deprecated(
-                    reason=f"Config settings are ignored for project {self}.",
-                    replacement=(
-                        "to use --use-pep517 or add a "
-                        "pyproject.toml file to the project"
-                    ),
-                    gone_in="24.0",
-                )
+            assert not self.config_settings
             self.use_pep517 = False
             return
 
@@ -754,8 +756,8 @@
 
         if os.path.exists(archive_path):
             response = ask_path_exists(
-                "The file {} exists. (i)gnore, (w)ipe, "
-                "(b)ackup, (a)bort ".format(display_path(archive_path)),
+                f"The file {display_path(archive_path)} exists. (i)gnore, (w)ipe, "
+                "(b)ackup, (a)bort ",
                 ("i", "w", "b", "a"),
             )
             if response == "i":
@@ -827,6 +829,13 @@
         )
 
         if self.editable and not self.is_wheel:
+            if self.config_settings:
+                logger.warning(
+                    "--config-settings ignored for legacy editable install of %s. "
+                    "Consider upgrading to a version of setuptools "
+                    "that supports PEP 660 (>= 64).",
+                    self,
+                )
             install_editable_legacy(
                 global_options=global_options if global_options is not None else [],
                 prefix=prefix,
@@ -905,7 +914,7 @@
             reason="--build-option and --global-option are deprecated.",
             issue=11859,
             replacement="to use --config-settings",
-            gone_in="24.0",
+            gone_in="24.2",
         )
         logger.warning(
             "Implying --no-binary=:all: due to the presence of "
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/req/req_set.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/req/req_set.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/req/req_set.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/req/req_set.py	2024-02-03 17:39:20.036082493 -0500
@@ -99,7 +99,7 @@
                         "or contact the package author to fix the version number"
                     ),
                     issue=12063,
-                    gone_in="24.0",
+                    gone_in="24.1",
                 )
             for dep in req.get_dist().iter_dependencies():
                 if any(isinstance(spec, LegacySpecifier) for spec in dep.specifier):
@@ -115,5 +115,5 @@
                             "or contact the package author to fix the version number"
                         ),
                         issue=12063,
-                        gone_in="24.0",
+                        gone_in="24.1",
                     )
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/req/req_uninstall.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/req/req_uninstall.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/req/req_uninstall.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/req/req_uninstall.py	2024-02-03 17:39:20.036082493 -0500
@@ -71,16 +71,16 @@
 
     entries = dist.iter_declared_entries()
     if entries is None:
-        msg = "Cannot uninstall {dist}, RECORD file not found.".format(dist=dist)
+        msg = f"Cannot uninstall {dist}, RECORD file not found."
         installer = dist.installer
         if not installer or installer == "pip":
-            dep = "{}=={}".format(dist.raw_name, dist.version)
+            dep = f"{dist.raw_name}=={dist.version}"
             msg += (
                 " You might be able to recover from this via: "
-                "'pip install --force-reinstall --no-deps {}'.".format(dep)
+                f"'pip install --force-reinstall --no-deps {dep}'."
             )
         else:
-            msg += " Hint: The package was installed by {}.".format(installer)
+            msg += f" Hint: The package was installed by {installer}."
         raise UninstallationError(msg)
 
     for entry in entries:
@@ -172,8 +172,7 @@
             folders.add(os.path.dirname(path))
         files.add(path)
 
-    # probably this one https://github.com/python/mypy/issues/390
-    _normcased_files = set(map(os.path.normcase, files))  # type: ignore
+    _normcased_files = set(map(os.path.normcase, files))
 
     folders = compact(folders)
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/resolution/legacy/resolver.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/resolution/legacy/resolver.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/resolution/legacy/resolver.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/resolution/legacy/resolver.py	2024-02-03 17:39:20.022082493 -0500
@@ -231,9 +231,7 @@
             tags = compatibility_tags.get_supported()
             if requirement_set.check_supported_wheels and not wheel.supported(tags):
                 raise InstallationError(
-                    "{} is not a supported wheel on this platform.".format(
-                        wheel.filename
-                    )
+                    f"{wheel.filename} is not a supported wheel on this platform."
                 )
 
         # This next bit is really a sanity check.
@@ -287,9 +285,9 @@
         )
         if does_not_satisfy_constraint:
             raise InstallationError(
-                "Could not satisfy constraints for '{}': "
+                f"Could not satisfy constraints for '{install_req.name}': "
                 "installation from path or url cannot be "
-                "constrained to a version".format(install_req.name)
+                "constrained to a version"
             )
         # If we're now installing a constraint, mark the existing
         # object for real installation.
@@ -398,9 +396,9 @@
                 # "UnicodeEncodeError: 'ascii' codec can't encode character"
                 # in Python 2 when the reason contains non-ascii characters.
                 "The candidate selected for download or install is a "
-                "yanked version: {candidate}\n"
-                "Reason for being yanked: {reason}"
-            ).format(candidate=best_candidate, reason=reason)
+                f"yanked version: {best_candidate}\n"
+                f"Reason for being yanked: {reason}"
+            )
             logger.warning(msg)
 
         return link
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py	2024-02-03 17:39:20.023082493 -0500
@@ -159,10 +159,7 @@
         return f"{self.name} {self.version}"
 
     def __repr__(self) -> str:
-        return "{class_name}({link!r})".format(
-            class_name=self.__class__.__name__,
-            link=str(self._link),
-        )
+        return f"{self.__class__.__name__}({str(self._link)!r})"
 
     def __hash__(self) -> int:
         return hash((self.__class__, self._link))
@@ -354,10 +351,7 @@
         return str(self.dist)
 
     def __repr__(self) -> str:
-        return "{class_name}({distribution!r})".format(
-            class_name=self.__class__.__name__,
-            distribution=self.dist,
-        )
+        return f"{self.__class__.__name__}({self.dist!r})"
 
     def __hash__(self) -> int:
         return hash((self.__class__, self.name, self.version))
@@ -455,11 +449,7 @@
         return "{}[{}] {}".format(name, ",".join(self.extras), rest)
 
     def __repr__(self) -> str:
-        return "{class_name}(base={base!r}, extras={extras!r})".format(
-            class_name=self.__class__.__name__,
-            base=self.base,
-            extras=self.extras,
-        )
+        return f"{self.__class__.__name__}(base={self.base!r}, extras={self.extras!r})"
 
     def __hash__(self) -> int:
         return hash((self.base, self.extras))
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py	2024-02-03 17:39:20.023082493 -0500
@@ -774,8 +774,8 @@
             info = "the requested packages"
 
         msg = (
-            "Cannot install {} because these package versions "
-            "have conflicting dependencies.".format(info)
+            f"Cannot install {info} because these package versions "
+            "have conflicting dependencies."
         )
         logger.critical(msg)
         msg = "\nThe conflict is caused by:"
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/requirements.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/requirements.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/requirements.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/requirements.py	2024-02-03 17:39:20.023082493 -0500
@@ -15,10 +15,7 @@
         return str(self.candidate)
 
     def __repr__(self) -> str:
-        return "{class_name}({candidate!r})".format(
-            class_name=self.__class__.__name__,
-            candidate=self.candidate,
-        )
+        return f"{self.__class__.__name__}({self.candidate!r})"
 
     @property
     def project_name(self) -> NormalizedName:
@@ -50,10 +47,7 @@
         return str(self._ireq.req)
 
     def __repr__(self) -> str:
-        return "{class_name}({requirement!r})".format(
-            class_name=self.__class__.__name__,
-            requirement=str(self._ireq.req),
-        )
+        return f"{self.__class__.__name__}({str(self._ireq.req)!r})"
 
     @property
     def project_name(self) -> NormalizedName:
@@ -116,10 +110,7 @@
         return f"Python {self.specifier}"
 
     def __repr__(self) -> str:
-        return "{class_name}({specifier!r})".format(
-            class_name=self.__class__.__name__,
-            specifier=str(self.specifier),
-        )
+        return f"{self.__class__.__name__}({str(self.specifier)!r})"
 
     @property
     def project_name(self) -> NormalizedName:
@@ -155,10 +146,7 @@
         return f"{self._name} (unavailable)"
 
     def __repr__(self) -> str:
-        return "{class_name}({name!r})".format(
-            class_name=self.__class__.__name__,
-            name=str(self._name),
-        )
+        return f"{self.__class__.__name__}({str(self._name)!r})"
 
     @property
     def project_name(self) -> NormalizedName:
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/utils/egg_link.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/utils/egg_link.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/utils/egg_link.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/utils/egg_link.py	2024-02-03 17:39:20.026082493 -0500
@@ -15,24 +15,31 @@
 ]
 
 
-def _egg_link_name(raw_name: str) -> str:
+def _egg_link_names(raw_name: str) -> List[str]:
     """
     Convert a Name metadata value to a .egg-link name, by applying
     the same substitution as pkg_resources's safe_name function.
     Note: we cannot use canonicalize_name because it has a different logic.
+
+    We also look for the raw name (without normalization) as setuptools 69 changed
+    the way it names .egg-link files (https://github.com/pypa/setuptools/issues/4167).
     """
-    return re.sub("[^A-Za-z0-9.]+", "-", raw_name) + ".egg-link"
+    return [
+        re.sub("[^A-Za-z0-9.]+", "-", raw_name) + ".egg-link",
+        f"{raw_name}.egg-link",
+    ]
 
 
 def egg_link_path_from_sys_path(raw_name: str) -> Optional[str]:
     """
     Look for a .egg-link file for project name, by walking sys.path.
     """
-    egg_link_name = _egg_link_name(raw_name)
+    egg_link_names = _egg_link_names(raw_name)
     for path_item in sys.path:
-        egg_link = os.path.join(path_item, egg_link_name)
-        if os.path.isfile(egg_link):
-            return egg_link
+        for egg_link_name in egg_link_names:
+            egg_link = os.path.join(path_item, egg_link_name)
+            if os.path.isfile(egg_link):
+                return egg_link
     return None
 
 
@@ -64,9 +71,10 @@
             sites.append(user_site)
         sites.append(site_packages)
 
-    egg_link_name = _egg_link_name(raw_name)
+    egg_link_names = _egg_link_names(raw_name)
     for site in sites:
-        egglink = os.path.join(site, egg_link_name)
-        if os.path.isfile(egglink):
-            return egglink
+        for egg_link_name in egg_link_names:
+            egglink = os.path.join(site, egg_link_name)
+            if os.path.isfile(egglink):
+                return egglink
     return None
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/utils/misc.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/utils/misc.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/utils/misc.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/utils/misc.py	2024-02-03 17:39:20.027082493 -0500
@@ -77,11 +77,7 @@
     pip_pkg_dir = os.path.join(os.path.dirname(__file__), "..", "..")
     pip_pkg_dir = os.path.abspath(pip_pkg_dir)
 
-    return "pip {} from {} (python {})".format(
-        __version__,
-        pip_pkg_dir,
-        get_major_minor_version(),
-    )
+    return f"pip {__version__} from {pip_pkg_dir} (python {get_major_minor_version()})"
 
 
 def normalize_version_info(py_version_info: Tuple[int, ...]) -> Tuple[int, int, int]:
@@ -145,9 +141,9 @@
     )
     if sys.version_info >= (3, 12):
         # See https://docs.python.org/3.12/whatsnew/3.12.html#shutil.
-        shutil.rmtree(dir, onexc=handler)
+        shutil.rmtree(dir, onexc=handler)  # type: ignore
     else:
-        shutil.rmtree(dir, onerror=handler)
+        shutil.rmtree(dir, onerror=handler)  # type: ignore
 
 
 def _onerror_ignore(*_args: Any) -> None:
@@ -279,13 +275,13 @@
 
 def format_size(bytes: float) -> str:
     if bytes > 1000 * 1000:
-        return "{:.1f} MB".format(bytes / 1000.0 / 1000)
+        return f"{bytes / 1000.0 / 1000:.1f} MB"
     elif bytes > 10 * 1000:
-        return "{} kB".format(int(bytes / 1000))
+        return f"{int(bytes / 1000)} kB"
     elif bytes > 1000:
-        return "{:.1f} kB".format(bytes / 1000.0)
+        return f"{bytes / 1000.0:.1f} kB"
     else:
-        return "{} bytes".format(int(bytes))
+        return f"{int(bytes)} bytes"
 
 
 def tabulate(rows: Iterable[Iterable[Any]]) -> Tuple[List[str], List[int]]:
@@ -522,9 +518,7 @@
     else:
         user = urllib.parse.quote(user)
         password = ":****"
-    return "{user}{password}@{netloc}".format(
-        user=user, password=password, netloc=netloc
-    )
+    return f"{user}{password}@{netloc}"
 
 
 def _transform_url(
@@ -592,7 +586,7 @@
         self.redacted = redacted
 
     def __repr__(self) -> str:
-        return "<HiddenText {!r}>".format(str(self))
+        return f"<HiddenText {str(self)!r}>"
 
     def __str__(self) -> str:
         return self.redacted
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/utils/wheel.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/utils/wheel.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/utils/wheel.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/utils/wheel.py	2024-02-03 17:39:20.027082493 -0500
@@ -28,7 +28,7 @@
         metadata = wheel_metadata(wheel_zip, info_dir)
         version = wheel_version(metadata)
     except UnsupportedWheel as e:
-        raise UnsupportedWheel("{} has an invalid wheel, {}".format(name, str(e)))
+        raise UnsupportedWheel(f"{name} has an invalid wheel, {str(e)}")
 
     check_compatibility(version, name)
 
@@ -60,9 +60,7 @@
     canonical_name = canonicalize_name(name)
     if not info_dir_name.startswith(canonical_name):
         raise UnsupportedWheel(
-            ".dist-info directory {!r} does not start with {!r}".format(
-                info_dir, canonical_name
-            )
+            f".dist-info directory {info_dir!r} does not start with {canonical_name!r}"
         )
 
     return info_dir
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/vcs/versioncontrol.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/vcs/versioncontrol.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/vcs/versioncontrol.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/vcs/versioncontrol.py	2024-02-03 17:39:20.031082493 -0500
@@ -405,9 +405,9 @@
         scheme, netloc, path, query, frag = urllib.parse.urlsplit(url)
         if "+" not in scheme:
             raise ValueError(
-                "Sorry, {!r} is a malformed VCS url. "
+                f"Sorry, {url!r} is a malformed VCS url. "
                 "The format is <vcs>+<protocol>://<url>, "
-                "e.g. svn+http://myrepo/svn/MyApp#egg=MyApp".format(url)
+                "e.g. svn+http://myrepo/svn/MyApp#egg=MyApp"
             )
         # Remove the vcs prefix.
         scheme = scheme.split("+", 1)[1]
@@ -417,9 +417,9 @@
             path, rev = path.rsplit("@", 1)
             if not rev:
                 raise InstallationError(
-                    "The URL {!r} has an empty revision (after @) "
+                    f"The URL {url!r} has an empty revision (after @) "
                     "which is not supported. Include a revision after @ "
-                    "or remove @ from the URL.".format(url)
+                    "or remove @ from the URL."
                 )
         url = urllib.parse.urlunsplit((scheme, netloc, path, query, ""))
         return url, rev, user_pass
@@ -566,7 +566,7 @@
             self.name,
             url,
         )
-        response = ask_path_exists("What to do?  {}".format(prompt[0]), prompt[1])
+        response = ask_path_exists(f"What to do?  {prompt[0]}", prompt[1])
 
         if response == "a":
             sys.exit(-1)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/wheel_builder.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/wheel_builder.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_internal/wheel_builder.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_internal/wheel_builder.py	2024-02-03 17:39:20.028082493 -0500
@@ -140,15 +140,15 @@
     w = Wheel(os.path.basename(wheel_path))
     if canonicalize_name(w.name) != canonical_name:
         raise InvalidWheelFilename(
-            "Wheel has unexpected file name: expected {!r}, "
-            "got {!r}".format(canonical_name, w.name),
+            f"Wheel has unexpected file name: expected {canonical_name!r}, "
+            f"got {w.name!r}",
         )
     dist = get_wheel_distribution(FilesystemWheel(wheel_path), canonical_name)
     dist_verstr = str(dist.version)
     if canonicalize_version(dist_verstr) != canonicalize_version(w.version):
         raise InvalidWheelFilename(
-            "Wheel has unexpected file name: expected {!r}, "
-            "got {!r}".format(dist_verstr, w.version),
+            f"Wheel has unexpected file name: expected {dist_verstr!r}, "
+            f"got {w.version!r}",
         )
     metadata_version_value = dist.metadata_version
     if metadata_version_value is None:
@@ -160,8 +160,7 @@
         raise UnsupportedWheel(msg)
     if metadata_version >= Version("1.2") and not isinstance(dist.version, Version):
         raise UnsupportedWheel(
-            "Metadata 1.2 mandates PEP 440 version, "
-            "but {!r} is not".format(dist_verstr)
+            f"Metadata 1.2 mandates PEP 440 version, but {dist_verstr!r} is not"
         )
 
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/compat.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/compat.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/compat.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/compat.py	2024-02-03 17:39:20.062082493 -0500
@@ -8,6 +8,7 @@
 
 import os
 import re
+import shutil
 import sys
 
 try:
@@ -33,9 +34,8 @@
 
     import urllib2
     from urllib2 import (Request, urlopen, URLError, HTTPError,
-                         HTTPBasicAuthHandler, HTTPPasswordMgr,
-                         HTTPHandler, HTTPRedirectHandler,
-                         build_opener)
+                         HTTPBasicAuthHandler, HTTPPasswordMgr, HTTPHandler,
+                         HTTPRedirectHandler, build_opener)
     if ssl:
         from urllib2 import HTTPSHandler
     import httplib
@@ -50,15 +50,15 @@
     # Leaving this around for now, in case it needs resurrecting in some way
     # _userprog = None
     # def splituser(host):
-        # """splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'."""
-        # global _userprog
-        # if _userprog is None:
-            # import re
-            # _userprog = re.compile('^(.*)@(.*)$')
-
-        # match = _userprog.match(host)
-        # if match: return match.group(1, 2)
-        # return None, host
+    # """splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'."""
+    # global _userprog
+    # if _userprog is None:
+    # import re
+    # _userprog = re.compile('^(.*)@(.*)$')
+
+    # match = _userprog.match(host)
+    # if match: return match.group(1, 2)
+    # return None, host
 
 else:  # pragma: no cover
     from io import StringIO
@@ -67,14 +67,12 @@
     from io import TextIOWrapper as file_type
     import builtins
     import configparser
-    import shutil
-    from urllib.parse import (urlparse, urlunparse, urljoin, quote,
-                              unquote, urlsplit, urlunsplit, splittype)
+    from urllib.parse import (urlparse, urlunparse, urljoin, quote, unquote,
+                              urlsplit, urlunsplit, splittype)
     from urllib.request import (urlopen, urlretrieve, Request, url2pathname,
-                                pathname2url,
-                                HTTPBasicAuthHandler, HTTPPasswordMgr,
-                                HTTPHandler, HTTPRedirectHandler,
-                                build_opener)
+                                pathname2url, HTTPBasicAuthHandler,
+                                HTTPPasswordMgr, HTTPHandler,
+                                HTTPRedirectHandler, build_opener)
     if ssl:
         from urllib.request import HTTPSHandler
     from urllib.error import HTTPError, URLError, ContentTooShortError
@@ -88,14 +86,13 @@
     from itertools import filterfalse
     filter = filter
 
-
 try:
     from ssl import match_hostname, CertificateError
-except ImportError: # pragma: no cover
+except ImportError:  # pragma: no cover
+
     class CertificateError(ValueError):
         pass
 
-
     def _dnsname_match(dn, hostname, max_wildcards=1):
         """Matching according to RFC 6125, section 6.4.3
 
@@ -145,7 +142,6 @@
         pat = re.compile(r'\A' + r'\.'.join(pats) + r'\Z', re.IGNORECASE)
         return pat.match(hostname)
 
-
     def match_hostname(cert, hostname):
         """Verify that *cert* (in decoded format as returned by
         SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125
@@ -178,24 +174,26 @@
                         dnsnames.append(value)
         if len(dnsnames) > 1:
             raise CertificateError("hostname %r "
-                "doesn't match either of %s"
-                % (hostname, ', '.join(map(repr, dnsnames))))
+                                   "doesn't match either of %s" %
+                                   (hostname, ', '.join(map(repr, dnsnames))))
         elif len(dnsnames) == 1:
             raise CertificateError("hostname %r "
-                "doesn't match %r"
-                % (hostname, dnsnames[0]))
+                                   "doesn't match %r" %
+                                   (hostname, dnsnames[0]))
         else:
             raise CertificateError("no appropriate commonName or "
-                "subjectAltName fields were found")
+                                   "subjectAltName fields were found")
 
 
 try:
     from types import SimpleNamespace as Container
 except ImportError:  # pragma: no cover
+
     class Container(object):
         """
         A generic container for when multiple values need to be returned
         """
+
         def __init__(self, **kwargs):
             self.__dict__.update(kwargs)
 
@@ -214,6 +212,7 @@
         path.
 
         """
+
         # Check that a given file can be accessed with the correct mode.
         # Additionally check that `file` is not a directory, as on Windows
         # directories pass the os.access check.
@@ -237,7 +236,7 @@
 
         if sys.platform == "win32":
             # The current directory takes precedence on Windows.
-            if not os.curdir in path:
+            if os.curdir not in path:
                 path.insert(0, os.curdir)
 
             # PATHEXT is necessary to check on Windows.
@@ -258,7 +257,7 @@
         seen = set()
         for dir in path:
             normdir = os.path.normcase(dir)
-            if not normdir in seen:
+            if normdir not in seen:
                 seen.add(normdir)
                 for thefile in files:
                     name = os.path.join(dir, thefile)
@@ -277,6 +276,7 @@
     from zipfile import ZipExtFile as BaseZipExtFile
 
     class ZipExtFile(BaseZipExtFile):
+
         def __init__(self, base):
             self.__dict__.update(base.__dict__)
 
@@ -288,6 +288,7 @@
             # return None, so if an exception occurred, it will propagate
 
     class ZipFile(BaseZipFile):
+
         def __enter__(self):
             return self
 
@@ -299,9 +300,11 @@
             base = BaseZipFile.open(self, *args, **kwargs)
             return ZipExtFile(base)
 
+
 try:
     from platform import python_implementation
-except ImportError: # pragma: no cover
+except ImportError:  # pragma: no cover
+
     def python_implementation():
         """Return a string identifying the Python implementation."""
         if 'PyPy' in sys.version:
@@ -312,12 +315,12 @@
             return 'IronPython'
         return 'CPython'
 
-import shutil
+
 import sysconfig
 
 try:
     callable = callable
-except NameError:   # pragma: no cover
+except NameError:  # pragma: no cover
     from collections.abc import Callable
 
     def callable(obj):
@@ -358,11 +361,11 @@
             raise TypeError("expect bytes or str, not %s" %
                             type(filename).__name__)
 
+
 try:
     from tokenize import detect_encoding
-except ImportError: # pragma: no cover
+except ImportError:  # pragma: no cover
     from codecs import BOM_UTF8, lookup
-    import re
 
     cookie_re = re.compile(r"coding[:=]\s*([-\w.]+)")
 
@@ -401,6 +404,7 @@
         bom_found = False
         encoding = None
         default = 'utf-8'
+
         def read_or_stop():
             try:
                 return readline()
@@ -430,8 +434,8 @@
                 if filename is None:
                     msg = "unknown encoding: " + encoding
                 else:
-                    msg = "unknown encoding for {!r}: {}".format(filename,
-                            encoding)
+                    msg = "unknown encoding for {!r}: {}".format(
+                        filename, encoding)
                 raise SyntaxError(msg)
 
             if bom_found:
@@ -440,7 +444,8 @@
                     if filename is None:
                         msg = 'encoding problem: utf-8'
                     else:
-                        msg = 'encoding problem for {!r}: utf-8'.format(filename)
+                        msg = 'encoding problem for {!r}: utf-8'.format(
+                            filename)
                     raise SyntaxError(msg)
                 encoding += '-sig'
             return encoding
@@ -467,6 +472,7 @@
 
         return default, [first, second]
 
+
 # For converting & <-> &amp; etc.
 try:
     from html import escape
@@ -479,12 +485,13 @@
 
 try:
     from collections import ChainMap
-except ImportError: # pragma: no cover
+except ImportError:  # pragma: no cover
     from collections import MutableMapping
 
     try:
         from reprlib import recursive_repr as _recursive_repr
     except ImportError:
+
         def _recursive_repr(fillvalue='...'):
             '''
             Decorator to make a repr function return fillvalue for a recursive
@@ -509,13 +516,15 @@
                 wrapper.__module__ = getattr(user_function, '__module__')
                 wrapper.__doc__ = getattr(user_function, '__doc__')
                 wrapper.__name__ = getattr(user_function, '__name__')
-                wrapper.__annotations__ = getattr(user_function, '__annotations__', {})
+                wrapper.__annotations__ = getattr(user_function,
+                                                  '__annotations__', {})
                 return wrapper
 
             return decorating_function
 
     class ChainMap(MutableMapping):
-        ''' A ChainMap groups multiple dicts (or other mappings) together
+        '''
+        A ChainMap groups multiple dicts (or other mappings) together
         to create a single, updateable view.
 
         The underlying mappings are stored in a list.  That list is public and can
@@ -524,7 +533,6 @@
         Lookups search the underlying mappings successively until a key is found.
         In contrast, writes, updates, and deletions only operate on the first
         mapping.
-
         '''
 
         def __init__(self, *maps):
@@ -532,7 +540,7 @@
             If no mappings are provided, a single empty dictionary is used.
 
             '''
-            self.maps = list(maps) or [{}]          # always at least one map
+            self.maps = list(maps) or [{}]  # always at least one map
 
         def __missing__(self, key):
             raise KeyError(key)
@@ -540,16 +548,19 @@
         def __getitem__(self, key):
             for mapping in self.maps:
                 try:
-                    return mapping[key]             # can't use 'key in mapping' with defaultdict
+                    return mapping[
+                        key]  # can't use 'key in mapping' with defaultdict
                 except KeyError:
                     pass
-            return self.__missing__(key)            # support subclasses that define __missing__
+            return self.__missing__(
+                key)  # support subclasses that define __missing__
 
         def get(self, key, default=None):
             return self[key] if key in self else default
 
         def __len__(self):
-            return len(set().union(*self.maps))     # reuses stored hash values if possible
+            return len(set().union(
+                *self.maps))  # reuses stored hash values if possible
 
         def __iter__(self):
             return iter(set().union(*self.maps))
@@ -576,12 +587,12 @@
 
         __copy__ = copy
 
-        def new_child(self):                        # like Django's Context.push()
+        def new_child(self):  # like Django's Context.push()
             'New ChainMap with a new dict followed by all previous maps.'
             return self.__class__({}, *self.maps)
 
         @property
-        def parents(self):                          # like Django's Context.pop()
+        def parents(self):  # like Django's Context.pop()
             'New ChainMap from maps[1:].'
             return self.__class__(*self.maps[1:])
 
@@ -592,7 +603,8 @@
             try:
                 del self.maps[0][key]
             except KeyError:
-                raise KeyError('Key not found in the first mapping: {!r}'.format(key))
+                raise KeyError(
+                    'Key not found in the first mapping: {!r}'.format(key))
 
         def popitem(self):
             'Remove and return an item pair from maps[0]. Raise KeyError is maps[0] is empty.'
@@ -606,15 +618,18 @@
             try:
                 return self.maps[0].pop(key, *args)
             except KeyError:
-                raise KeyError('Key not found in the first mapping: {!r}'.format(key))
+                raise KeyError(
+                    'Key not found in the first mapping: {!r}'.format(key))
 
         def clear(self):
             'Clear maps[0], leaving maps[1:] intact.'
             self.maps[0].clear()
 
+
 try:
     from importlib.util import cache_from_source  # Python >= 3.4
 except ImportError:  # pragma: no cover
+
     def cache_from_source(path, debug_override=None):
         assert path.endswith('.py')
         if debug_override is None:
@@ -625,12 +640,13 @@
             suffix = 'o'
         return path + suffix
 
+
 try:
     from collections import OrderedDict
-except ImportError: # pragma: no cover
-## {{{ http://code.activestate.com/recipes/576693/ (r9)
-# Backport of OrderedDict() class that runs on Python 2.4, 2.5, 2.6, 2.7 and pypy.
-# Passes Python2.7's test suite and incorporates all the latest updates.
+except ImportError:  # pragma: no cover
+    # {{{ http://code.activestate.com/recipes/576693/ (r9)
+    # Backport of OrderedDict() class that runs on Python 2.4, 2.5, 2.6, 2.7 and pypy.
+    # Passes Python2.7's test suite and incorporates all the latest updates.
     try:
         from thread import get_ident as _get_ident
     except ImportError:
@@ -641,9 +657,9 @@
     except ImportError:
         pass
 
-
     class OrderedDict(dict):
         'Dictionary that remembers insertion order'
+
         # An inherited dict maps keys to values.
         # The inherited dict provides __getitem__, __len__, __contains__, and get.
         # The remaining methods are order-aware.
@@ -661,11 +677,12 @@
 
             '''
             if len(args) > 1:
-                raise TypeError('expected at most 1 arguments, got %d' % len(args))
+                raise TypeError('expected at most 1 arguments, got %d' %
+                                len(args))
             try:
                 self.__root
             except AttributeError:
-                self.__root = root = []                     # sentinel node
+                self.__root = root = []  # sentinel node
                 root[:] = [root, root, None]
                 self.__map = {}
             self.__update(*args, **kwds)
@@ -779,7 +796,7 @@
             '''
             if len(args) > 2:
                 raise TypeError('update() takes at most 2 positional '
-                                'arguments (%d given)' % (len(args),))
+                                'arguments (%d given)' % (len(args), ))
             elif not args:
                 raise TypeError('update() takes at least 1 argument (0 given)')
             self = args[0]
@@ -825,14 +842,15 @@
 
         def __repr__(self, _repr_running=None):
             'od.__repr__() <==> repr(od)'
-            if not _repr_running: _repr_running = {}
+            if not _repr_running:
+                _repr_running = {}
             call_key = id(self), _get_ident()
             if call_key in _repr_running:
                 return '...'
             _repr_running[call_key] = 1
             try:
                 if not self:
-                    return '%s()' % (self.__class__.__name__,)
+                    return '%s()' % (self.__class__.__name__, )
                 return '%s(%r)' % (self.__class__.__name__, self.items())
             finally:
                 del _repr_running[call_key]
@@ -844,8 +862,8 @@
             for k in vars(OrderedDict()):
                 inst_dict.pop(k, None)
             if inst_dict:
-                return (self.__class__, (items,), inst_dict)
-            return self.__class__, (items,)
+                return (self.__class__, (items, ), inst_dict)
+            return self.__class__, (items, )
 
         def copy(self):
             'od.copy() -> a shallow copy of od'
@@ -868,7 +886,8 @@
 
             '''
             if isinstance(other, OrderedDict):
-                return len(self)==len(other) and self.items() == other.items()
+                return len(self) == len(
+                    other) and self.items() == other.items()
             return dict.__eq__(self, other)
 
         def __ne__(self, other):
@@ -888,19 +907,18 @@
             "od.viewitems() -> a set-like object providing a view on od's items"
             return ItemsView(self)
 
+
 try:
     from logging.config import BaseConfigurator, valid_ident
-except ImportError: # pragma: no cover
+except ImportError:  # pragma: no cover
     IDENTIFIER = re.compile('^[a-z_][a-z0-9_]*$', re.I)
 
-
     def valid_ident(s):
         m = IDENTIFIER.match(s)
         if not m:
             raise ValueError('Not a valid Python identifier: %r' % s)
         return True
 
-
     # The ConvertingXXX classes are wrappers around standard Python containers,
     # and they serve to convert any suitable values in the container. The
     # conversion converts base dicts, lists and tuples to their wrapped
@@ -916,7 +934,7 @@
         def __getitem__(self, key):
             value = dict.__getitem__(self, key)
             result = self.configurator.convert(value)
-            #If the converted value is different, save for next time
+            # If the converted value is different, save for next time
             if value is not result:
                 self[key] = result
                 if type(result) in (ConvertingDict, ConvertingList,
@@ -928,7 +946,7 @@
         def get(self, key, default=None):
             value = dict.get(self, key, default)
             result = self.configurator.convert(value)
-            #If the converted value is different, save for next time
+            # If the converted value is different, save for next time
             if value is not result:
                 self[key] = result
                 if type(result) in (ConvertingDict, ConvertingList,
@@ -949,10 +967,11 @@
 
     class ConvertingList(list):
         """A converting list wrapper."""
+
         def __getitem__(self, key):
             value = list.__getitem__(self, key)
             result = self.configurator.convert(value)
-            #If the converted value is different, save for next time
+            # If the converted value is different, save for next time
             if value is not result:
                 self[key] = result
                 if type(result) in (ConvertingDict, ConvertingList,
@@ -972,6 +991,7 @@
 
     class ConvertingTuple(tuple):
         """A converting tuple wrapper."""
+
         def __getitem__(self, key):
             value = tuple.__getitem__(self, key)
             result = self.configurator.convert(value)
@@ -995,8 +1015,8 @@
         DIGIT_PATTERN = re.compile(r'^\d+$')
 
         value_converters = {
-            'ext' : 'ext_convert',
-            'cfg' : 'cfg_convert',
+            'ext': 'ext_convert',
+            'cfg': 'cfg_convert',
         }
 
         # We might want to use a different one, e.g. importlib
@@ -1042,7 +1062,6 @@
             else:
                 rest = rest[m.end():]
                 d = self.config[m.groups()[0]]
-                #print d, rest
                 while rest:
                     m = self.DOT_PATTERN.match(rest)
                     if m:
@@ -1055,7 +1074,9 @@
                                 d = d[idx]
                             else:
                                 try:
-                                    n = int(idx) # try as number first (most likely)
+                                    n = int(
+                                        idx
+                                    )  # try as number first (most likely)
                                     d = d[n]
                                 except TypeError:
                                     d = d[idx]
@@ -1064,7 +1085,7 @@
                     else:
                         raise ValueError('Unable to convert '
                                          '%r at %r' % (value, rest))
-            #rest should be empty
+            # rest should be empty
             return d
 
         def convert(self, value):
@@ -1073,14 +1094,15 @@
             replaced by their converting alternatives. Strings are checked to
             see if they have a conversion format and are converted if they do.
             """
-            if not isinstance(value, ConvertingDict) and isinstance(value, dict):
+            if not isinstance(value, ConvertingDict) and isinstance(
+                    value, dict):
                 value = ConvertingDict(value)
                 value.configurator = self
-            elif not isinstance(value, ConvertingList) and isinstance(value, list):
+            elif not isinstance(value, ConvertingList) and isinstance(
+                    value, list):
                 value = ConvertingList(value)
                 value.configurator = self
-            elif not isinstance(value, ConvertingTuple) and\
-                     isinstance(value, tuple):
+            elif not isinstance(value, ConvertingTuple) and isinstance(value, tuple):
                 value = ConvertingTuple(value)
                 value.configurator = self
             elif isinstance(value, string_types):
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/database.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/database.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/database.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/database.py	2024-02-03 17:39:20.062082493 -0500
@@ -1,6 +1,6 @@
 # -*- coding: utf-8 -*-
 #
-# Copyright (C) 2012-2017 The Python Software Foundation.
+# Copyright (C) 2012-2023 The Python Software Foundation.
 # See LICENSE.txt and CONTRIBUTORS.txt.
 #
 """PEP 376 implementation."""
@@ -25,11 +25,10 @@
 from .util import (parse_requirement, cached_property, parse_name_and_version,
                    read_exports, write_exports, CSVReader, CSVWriter)
 
-
-__all__ = ['Distribution', 'BaseInstalledDistribution',
-           'InstalledDistribution', 'EggInfoDistribution',
-           'DistributionPath']
-
+__all__ = [
+    'Distribution', 'BaseInstalledDistribution', 'InstalledDistribution',
+    'EggInfoDistribution', 'DistributionPath'
+]
 
 logger = logging.getLogger(__name__)
 
@@ -46,6 +45,7 @@
     """
     A simple cache mapping names and .dist-info paths to distributions
     """
+
     def __init__(self):
         """
         Initialise an instance. There is normally one for each DistributionPath.
@@ -76,6 +76,7 @@
     """
     Represents a set of distributions installed on a path (typically sys.path).
     """
+
     def __init__(self, path=None, include_egg=False):
         """
         Create an instance from a path, optionally including legacy (distutils/
@@ -111,7 +112,6 @@
         self._cache.clear()
         self._cache_egg.clear()
 
-
     def _yield_distributions(self):
         """
         Yield .dist-info and/or .egg(-info) distributions.
@@ -134,11 +134,13 @@
                     continue
                 try:
                     if self._include_dist and entry.endswith(DISTINFO_EXT):
-                        possible_filenames = [METADATA_FILENAME,
-                                              WHEEL_METADATA_FILENAME,
-                                              LEGACY_METADATA_FILENAME]
+                        possible_filenames = [
+                            METADATA_FILENAME, WHEEL_METADATA_FILENAME,
+                            LEGACY_METADATA_FILENAME
+                        ]
                         for metadata_filename in possible_filenames:
-                            metadata_path = posixpath.join(entry, metadata_filename)
+                            metadata_path = posixpath.join(
+                                entry, metadata_filename)
                             pydist = finder.find(metadata_path)
                             if pydist:
                                 break
@@ -146,13 +148,15 @@
                             continue
 
                         with contextlib.closing(pydist.as_stream()) as stream:
-                            metadata = Metadata(fileobj=stream, scheme='legacy')
+                            metadata = Metadata(fileobj=stream,
+                                                scheme='legacy')
                         logger.debug('Found %s', r.path)
                         seen.add(r.path)
-                        yield new_dist_class(r.path, metadata=metadata,
+                        yield new_dist_class(r.path,
+                                             metadata=metadata,
                                              env=self)
-                    elif self._include_egg and entry.endswith(('.egg-info',
-                                                              '.egg')):
+                    elif self._include_egg and entry.endswith(
+                            ('.egg-info', '.egg')):
                         logger.debug('Found %s', r.path)
                         seen.add(r.path)
                         yield old_dist_class(r.path, self)
@@ -271,7 +275,7 @@
                 matcher = self._scheme.matcher('%s (%s)' % (name, version))
             except ValueError:
                 raise DistlibException('invalid name or version: %r, %r' %
-                                      (name, version))
+                                       (name, version))
 
         for dist in self.get_distributions():
             # We hit a problem on Travis where enum34 was installed and doesn't
@@ -346,12 +350,12 @@
         """
         self.metadata = metadata
         self.name = metadata.name
-        self.key = self.name.lower()    # for case-insensitive comparisons
+        self.key = self.name.lower()  # for case-insensitive comparisons
         self.version = metadata.version
         self.locator = None
         self.digest = None
-        self.extras = None      # additional features requested
-        self.context = None     # environment marker overrides
+        self.extras = None  # additional features requested
+        self.context = None  # environment marker overrides
         self.download_urls = set()
         self.digests = {}
 
@@ -362,7 +366,7 @@
         """
         return self.metadata.source_url
 
-    download_url = source_url   # Backward compatibility
+    download_url = source_url  # Backward compatibility
 
     @property
     def name_and_version(self):
@@ -386,10 +390,10 @@
     def _get_requirements(self, req_attr):
         md = self.metadata
         reqts = getattr(md, req_attr)
-        logger.debug('%s: got requirements %r from metadata: %r', self.name, req_attr,
-                     reqts)
-        return set(md.get_requirements(reqts, extras=self.extras,
-                                       env=self.context))
+        logger.debug('%s: got requirements %r from metadata: %r', self.name,
+                     req_attr, reqts)
+        return set(
+            md.get_requirements(reqts, extras=self.extras, env=self.context))
 
     @property
     def run_requires(self):
@@ -426,12 +430,11 @@
             matcher = scheme.matcher(r.requirement)
         except UnsupportedVersionError:
             # XXX compat-mode if cannot read the version
-            logger.warning('could not read version %r - using name only',
-                           req)
+            logger.warning('could not read version %r - using name only', req)
             name = req.split()[0]
             matcher = scheme.matcher(name)
 
-        name = matcher.key   # case-insensitive
+        name = matcher.key  # case-insensitive
 
         result = False
         for p in self.provides:
@@ -466,9 +469,8 @@
         if type(other) is not type(self):
             result = False
         else:
-            result = (self.name == other.name and
-                      self.version == other.version and
-                      self.source_url == other.source_url)
+            result = (self.name == other.name and self.version == other.version
+                      and self.source_url == other.source_url)
         return result
 
     def __hash__(self):
@@ -559,8 +561,8 @@
             if r is None:
                 r = finder.find(LEGACY_METADATA_FILENAME)
             if r is None:
-                raise ValueError('no %s found in %s' % (METADATA_FILENAME,
-                                                        path))
+                raise ValueError('no %s found in %s' %
+                                 (METADATA_FILENAME, path))
             with contextlib.closing(r.as_stream()) as stream:
                 metadata = Metadata(fileobj=stream, scheme='legacy')
 
@@ -571,7 +573,7 @@
 
         r = finder.find('REQUESTED')
         self.requested = r is not None
-        p  = os.path.join(path, 'top_level.txt')
+        p = os.path.join(path, 'top_level.txt')
         if os.path.exists(p):
             with open(p, 'rb') as f:
                 data = f.read().decode('utf-8')
@@ -596,14 +598,14 @@
         with contextlib.closing(r.as_stream()) as stream:
             with CSVReader(stream=stream) as record_reader:
                 # Base location is parent dir of .dist-info dir
-                #base_location = os.path.dirname(self.path)
-                #base_location = os.path.abspath(base_location)
+                # base_location = os.path.dirname(self.path)
+                # base_location = os.path.abspath(base_location)
                 for row in record_reader:
                     missing = [None for i in range(len(row), 3)]
                     path, checksum, size = row + missing
-                    #if not os.path.isabs(path):
-                    #    path = path.replace('/', os.sep)
-                    #    path = os.path.join(base_location, path)
+                    # if not os.path.isabs(path):
+                    #     path = path.replace('/', os.sep)
+                    #     path = os.path.join(base_location, path)
                     results.append((path, checksum, size))
         return results
 
@@ -701,8 +703,8 @@
                     size = '%d' % os.path.getsize(path)
                     with open(path, 'rb') as fp:
                         hash_value = self.get_hash(fp.read())
-                if path.startswith(base) or (base_under_prefix and
-                                             path.startswith(prefix)):
+                if path.startswith(base) or (base_under_prefix
+                                             and path.startswith(prefix)):
                     path = os.path.relpath(path, base)
                 writer.writerow((path, hash_value, size))
 
@@ -744,7 +746,8 @@
                     with open(path, 'rb') as f:
                         actual_hash = self.get_hash(f.read(), hasher)
                         if actual_hash != hash_value:
-                            mismatches.append((path, 'hash', hash_value, actual_hash))
+                            mismatches.append(
+                                (path, 'hash', hash_value, actual_hash))
         return mismatches
 
     @cached_property
@@ -791,7 +794,7 @@
         for key in ('prefix', 'lib', 'headers', 'scripts', 'data'):
             path = paths[key]
             if os.path.isdir(paths[key]):
-                lines.append('%s=%s' % (key,  path))
+                lines.append('%s=%s' % (key, path))
         for ns in paths.get('namespace', ()):
             lines.append('namespace=%s' % ns)
 
@@ -854,8 +857,8 @@
                 yield path
 
     def __eq__(self, other):
-        return (isinstance(other, InstalledDistribution) and
-                self.path == other.path)
+        return (isinstance(other, InstalledDistribution)
+                and self.path == other.path)
 
     # See http://docs.python.org/reference/datamodel#object.__hash__
     __hash__ = object.__hash__
@@ -867,13 +870,14 @@
     if the given path happens to be a directory, the metadata is read from the
     file ``PKG-INFO`` under that directory."""
 
-    requested = True    # as we have no way of knowing, assume it was
+    requested = True  # as we have no way of knowing, assume it was
     shared_locations = {}
 
     def __init__(self, path, env=None):
+
         def set_name_and_version(s, n, v):
             s.name = n
-            s.key = n.lower()   # for case-insensitive comparisons
+            s.key = n.lower()  # for case-insensitive comparisons
             s.version = v
 
         self.path = path
@@ -903,15 +907,18 @@
             lines = data.splitlines()
             for line in lines:
                 line = line.strip()
-                if line.startswith('['):
-                    logger.warning('Unexpected line: quitting requirement scan: %r',
-                                   line)
+                # sectioned files have bare newlines (separating sections)
+                if not line:  # pragma: no cover
+                    continue
+                if line.startswith('['):  # pragma: no cover
+                    logger.warning(
+                        'Unexpected line: quitting requirement scan: %r', line)
                     break
                 r = parse_requirement(line)
-                if not r:
+                if not r:  # pragma: no cover
                     logger.warning('Not recognised as a requirement: %r', line)
                     continue
-                if r.extras:
+                if r.extras:  # pragma: no cover
                     logger.warning('extra requirements in requires.txt are '
                                    'not supported')
                 if not r.constraints:
@@ -952,7 +959,8 @@
                 metadata = Metadata(fileobj=fileobj, scheme='legacy')
                 try:
                     data = zipf.get_data('EGG-INFO/requires.txt')
-                    tl_data = zipf.get_data('EGG-INFO/top_level.txt').decode('utf-8')
+                    tl_data = zipf.get_data('EGG-INFO/top_level.txt').decode(
+                        'utf-8')
                     requires = parse_requires_data(data.decode('utf-8'))
                 except IOError:
                     requires = None
@@ -982,8 +990,8 @@
         return metadata
 
     def __repr__(self):
-        return '<EggInfoDistribution %r %s at %r>' % (
-            self.name, self.version, self.path)
+        return '<EggInfoDistribution %r %s at %r>' % (self.name, self.version,
+                                                      self.path)
 
     def __str__(self):
         return "%s %s" % (self.name, self.version)
@@ -1039,7 +1047,7 @@
                         logger.warning('Non-existent file: %s', p)
                         if p.endswith(('.pyc', '.pyo')):
                             continue
-                        #otherwise fall through and fail
+                        # otherwise fall through and fail
                     if not os.path.isdir(p):
                         result.append((p, _md5(p), _size(p)))
             result.append((record_path, None, None))
@@ -1075,12 +1083,13 @@
                                 yield line
 
     def __eq__(self, other):
-        return (isinstance(other, EggInfoDistribution) and
-                self.path == other.path)
+        return (isinstance(other, EggInfoDistribution)
+                and self.path == other.path)
 
     # See http://docs.python.org/reference/datamodel#object.__hash__
     __hash__ = object.__hash__
 
+
 new_dist_class = InstalledDistribution
 old_dist_class = EggInfoDistribution
 
@@ -1114,7 +1123,7 @@
         """
         self.adjacency_list[distribution] = []
         self.reverse_list[distribution] = []
-        #self.missing[distribution] = []
+        # self.missing[distribution] = []
 
     def add_edge(self, x, y, label=None):
         """Add an edge from distribution *x* to distribution *y* with the given
@@ -1174,7 +1183,7 @@
             if len(adjs) == 0 and not skip_disconnected:
                 disconnected.append(dist)
             for other, label in adjs:
-                if not label is None:
+                if label is not None:
                     f.write('"%s" -> "%s" [label="%s"]\n' %
                             (dist.name, other.name, label))
                 else:
@@ -1252,8 +1261,8 @@
 
     # now make the edges
     for dist in dists:
-        requires = (dist.run_requires | dist.meta_requires |
-                    dist.build_requires | dist.dev_requires)
+        requires = (dist.run_requires | dist.meta_requires
+                    | dist.build_requires | dist.dev_requires)
         for req in requires:
             try:
                 matcher = scheme.matcher(req)
@@ -1264,7 +1273,7 @@
                 name = req.split()[0]
                 matcher = scheme.matcher(name)
 
-            name = matcher.key   # case-insensitive
+            name = matcher.key  # case-insensitive
 
             matched = False
             if name in provided:
@@ -1324,7 +1333,7 @@
 
     req = set()  # required distributions
     todo = graph.adjacency_list[dist]  # list of nodes we should inspect
-    seen = set(t[0] for t in todo) # already added to todo
+    seen = set(t[0] for t in todo)  # already added to todo
 
     while todo:
         d = todo.pop()[0]
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/index.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/index.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/index.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/index.py	2024-02-03 17:39:20.062082493 -0500
@@ -1,6 +1,6 @@
 # -*- coding: utf-8 -*-
 #
-# Copyright (C) 2013 Vinay Sajip.
+# Copyright (C) 2013-2023 Vinay Sajip.
 # Licensed to the Python Software Foundation under a contributor agreement.
 # See LICENSE.txt and CONTRIBUTORS.txt.
 #
@@ -25,6 +25,7 @@
 DEFAULT_INDEX = 'https://pypi.org/pypi'
 DEFAULT_REALM = 'pypi'
 
+
 class PackageIndex(object):
     """
     This class represents a package index compatible with PyPI, the Python
@@ -119,7 +120,7 @@
         d = metadata.todict()
         d[':action'] = 'verify'
         request = self.encode_request(d.items(), [])
-        response = self.send_request(request)
+        self.send_request(request)
         d[':action'] = 'submit'
         request = self.encode_request(d.items(), [])
         return self.send_request(request)
@@ -358,8 +359,7 @@
                                       keystore)
         rc, stdout, stderr = self.run_command(cmd)
         if rc not in (0, 1):
-            raise DistlibException('verify command failed with error '
-                             'code %s' % rc)
+            raise DistlibException('verify command failed with error code %s' % rc)
         return rc == 0
 
     def download_file(self, url, destfile, digest=None, reporthook=None):
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/__init__.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/__init__.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/__init__.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/__init__.py	2024-02-03 17:39:20.062082493 -0500
@@ -1,23 +1,33 @@
 # -*- coding: utf-8 -*-
 #
-# Copyright (C) 2012-2022 Vinay Sajip.
+# Copyright (C) 2012-2023 Vinay Sajip.
 # Licensed to the Python Software Foundation under a contributor agreement.
 # See LICENSE.txt and CONTRIBUTORS.txt.
 #
 import logging
 
-__version__ = '0.3.6'
+__version__ = '0.3.8'
+
 
 class DistlibException(Exception):
     pass
 
+
 try:
     from logging import NullHandler
-except ImportError: # pragma: no cover
+except ImportError:  # pragma: no cover
+
     class NullHandler(logging.Handler):
-        def handle(self, record): pass
-        def emit(self, record): pass
-        def createLock(self): self.lock = None
+
+        def handle(self, record):
+            pass
+
+        def emit(self, record):
+            pass
+
+        def createLock(self):
+            self.lock = None
+
 
 logger = logging.getLogger(__name__)
 logger.addHandler(NullHandler())
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/locators.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/locators.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/locators.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/locators.py	2024-02-03 17:39:20.062082493 -0500
@@ -1,6 +1,6 @@
 # -*- coding: utf-8 -*-
 #
-# Copyright (C) 2012-2015 Vinay Sajip.
+# Copyright (C) 2012-2023 Vinay Sajip.
 # Licensed to the Python Software Foundation under a contributor agreement.
 # See LICENSE.txt and CONTRIBUTORS.txt.
 #
@@ -38,6 +38,7 @@
 HTML_CONTENT_TYPE = re.compile('text/html|application/x(ht)?ml')
 DEFAULT_INDEX = 'https://pypi.org/pypi'
 
+
 def get_all_distribution_names(url=None):
     """
     Return all distribution names known by an index.
@@ -52,6 +53,7 @@
     finally:
         client('close')()
 
+
 class RedirectHandler(BaseRedirectHandler):
     """
     A class to work around a bug in some Python 3.2.x releases.
@@ -83,6 +85,7 @@
 
     http_error_301 = http_error_303 = http_error_307 = http_error_302
 
+
 class Locator(object):
     """
     A base class for locators - things that locate distributions.
@@ -272,7 +275,7 @@
                             'python-version': ', '.join(
                                 ['.'.join(list(v[2:])) for v in wheel.pyver]),
                         }
-            except Exception as e:  # pragma: no cover
+            except Exception:  # pragma: no cover
                 logger.warning('invalid path for wheel: %s', path)
         elif not path.endswith(self.downloadable_extensions):  # pragma: no cover
             logger.debug('Not downloadable: %s', path)
@@ -293,7 +296,6 @@
                                 'filename': filename,
                                 'url': urlunparse((scheme, netloc, origpath,
                                                    params, query, '')),
-                                #'packagetype': 'sdist',
                             }
                             if pyver:  # pragma: no cover
                                 result['python-version'] = pyver
@@ -382,12 +384,9 @@
                     else:
                         if prereleases or not vcls(k).is_prerelease:
                             slist.append(k)
-                        # else:
-                            # logger.debug('skipping pre-release '
-                                         # 'version %s of %s', k, matcher.name)
                 except Exception:  # pragma: no cover
                     logger.warning('error matching %s with %r', matcher, k)
-                    pass # slist.append(k)
+                    pass  # slist.append(k)
             if len(slist) > 1:
                 slist = sorted(slist, key=scheme.key)
             if slist:
@@ -456,6 +455,7 @@
                     result['digests'][url] = digest
         return result
 
+
 class PyPIJSONLocator(Locator):
     """
     This locator uses PyPI's JSON interface. It's very limited in functionality
@@ -476,7 +476,7 @@
         url = urljoin(self.base_url, '%s/json' % quote(name))
         try:
             resp = self.opener.open(url)
-            data = resp.read().decode() # for now
+            data = resp.read().decode()  # for now
             d = json.loads(data)
             md = Metadata(scheme=self.scheme)
             data = d['info']
@@ -487,7 +487,7 @@
             md.summary = data.get('summary')
             dist = Distribution(md)
             dist.locator = self
-            urls = d['urls']
+            # urls = d['urls']
             result[md.version] = dist
             for info in d['urls']:
                 url = info['url']
@@ -745,7 +745,7 @@
                             try:
                                 self._seen.add(link)
                                 if (not self._process_download(link) and
-                                    self._should_queue(link, url, rel)):
+                                        self._should_queue(link, url, rel)):
                                     logger.debug('Queueing %s from %s', link, url)
                                     self._to_fetch.put(link)
                             except MetadataInvalidError:  # e.g. invalid versions
@@ -756,7 +756,7 @@
                 # always do this, to avoid hangs :-)
                 self._to_fetch.task_done()
             if not url:
-                #logger.debug('Sentinel seen, quitting.')
+                # logger.debug('Sentinel seen, quitting.')
                 break
 
     def get_page(self, url):
@@ -832,6 +832,7 @@
             result.add(match.group(1))
         return result
 
+
 class DirectoryLocator(Locator):
     """
     This class locates distributions in a directory tree.
@@ -897,6 +898,7 @@
                 break
         return result
 
+
 class JSONLocator(Locator):
     """
     This locator uses special extended metadata (not available on PyPI) and is
@@ -935,6 +937,7 @@
                 result['urls'].setdefault(dist.version, set()).add(info['url'])
         return result
 
+
 class DistPathLocator(Locator):
     """
     This locator finds installed distributions in a path. It can be useful for
@@ -1245,7 +1248,7 @@
             if name not in self.dists_by_name:
                 self.add_distribution(dist)
             else:
-                #import pdb; pdb.set_trace()
+                # import pdb; pdb.set_trace()
                 other = self.dists_by_name[name]
                 if other != dist:
                     self.try_to_replace(dist, other, problems)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/manifest.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/manifest.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/manifest.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/manifest.py	2024-02-03 17:39:20.062082493 -0500
@@ -1,6 +1,6 @@
 # -*- coding: utf-8 -*-
 #
-# Copyright (C) 2012-2013 Python Software Foundation.
+# Copyright (C) 2012-2023 Python Software Foundation.
 # See LICENSE.txt and CONTRIBUTORS.txt.
 #
 """
@@ -34,9 +34,11 @@
 #
 _PYTHON_VERSION = sys.version_info[:2]
 
+
 class Manifest(object):
-    """A list of files built by on exploring the filesystem and filtered by
-    applying various patterns to what we find there.
+    """
+    A list of files built by exploring the filesystem and filtered by applying various
+    patterns to what we find there.
     """
 
     def __init__(self, base=None):
@@ -154,10 +156,7 @@
 
         elif action == 'exclude':
             for pattern in patterns:
-                found = self._exclude_pattern(pattern, anchor=True)
-                #if not found:
-                #    logger.warning('no previously-included files '
-                #                   'found matching %r', pattern)
+                self._exclude_pattern(pattern, anchor=True)
 
         elif action == 'global-include':
             for pattern in patterns:
@@ -167,11 +166,7 @@
 
         elif action == 'global-exclude':
             for pattern in patterns:
-                found = self._exclude_pattern(pattern, anchor=False)
-                #if not found:
-                #    logger.warning('no previously-included files '
-                #                   'matching %r found anywhere in '
-                #                   'distribution', pattern)
+                self._exclude_pattern(pattern, anchor=False)
 
         elif action == 'recursive-include':
             for pattern in patterns:
@@ -181,11 +176,7 @@
 
         elif action == 'recursive-exclude':
             for pattern in patterns:
-                found = self._exclude_pattern(pattern, prefix=thedir)
-                #if not found:
-                #    logger.warning('no previously-included files '
-                #                   'matching %r found under directory %r',
-                #                   pattern, thedir)
+                self._exclude_pattern(pattern, prefix=thedir)
 
         elif action == 'graft':
             if not self._include_pattern(None, prefix=dirpattern):
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/markers.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/markers.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/markers.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/markers.py	2024-02-03 17:39:20.062082493 -0500
@@ -1,6 +1,6 @@
 # -*- coding: utf-8 -*-
 #
-# Copyright (C) 2012-2017 Vinay Sajip.
+# Copyright (C) 2012-2023 Vinay Sajip.
 # Licensed to the Python Software Foundation under a contributor agreement.
 # See LICENSE.txt and CONTRIBUTORS.txt.
 #
@@ -19,26 +19,32 @@
 
 from .compat import string_types
 from .util import in_venv, parse_marker
-from .version import NormalizedVersion as NV
+from .version import LegacyVersion as LV
 
 __all__ = ['interpret']
 
-_VERSION_PATTERN = re.compile(r'((\d+(\.\d+)*\w*)|\'(\d+(\.\d+)*\w*)\'|\"(\d+(\.\d+)*\w*)\")')
+_VERSION_PATTERN = re.compile(
+    r'((\d+(\.\d+)*\w*)|\'(\d+(\.\d+)*\w*)\'|\"(\d+(\.\d+)*\w*)\")')
+_VERSION_MARKERS = {'python_version', 'python_full_version'}
+
+
+def _is_version_marker(s):
+    return isinstance(s, string_types) and s in _VERSION_MARKERS
+
 
 def _is_literal(o):
     if not isinstance(o, string_types) or not o:
         return False
     return o[0] in '\'"'
 
+
 def _get_versions(s):
-    result = []
-    for m in _VERSION_PATTERN.finditer(s):
-        result.append(NV(m.groups()[0]))
-    return set(result)
+    return {LV(m.groups()[0]) for m in _VERSION_PATTERN.finditer(s)}
+
 
 class Evaluator(object):
     """
-    This class is used to evaluate marker expessions.
+    This class is used to evaluate marker expressions.
     """
 
     operations = {
@@ -46,10 +52,10 @@
         '===': lambda x, y: x == y,
         '~=': lambda x, y: x == y or x > y,
         '!=': lambda x, y: x != y,
-        '<':  lambda x, y: x < y,
-        '<=':  lambda x, y: x == y or x < y,
-        '>':  lambda x, y: x > y,
-        '>=':  lambda x, y: x == y or x > y,
+        '<': lambda x, y: x < y,
+        '<=': lambda x, y: x == y or x < y,
+        '>': lambda x, y: x > y,
+        '>=': lambda x, y: x == y or x > y,
         'and': lambda x, y: x and y,
         'or': lambda x, y: x or y,
         'in': lambda x, y: x in y,
@@ -76,23 +82,27 @@
             elhs = expr['lhs']
             erhs = expr['rhs']
             if _is_literal(expr['lhs']) and _is_literal(expr['rhs']):
-                raise SyntaxError('invalid comparison: %s %s %s' % (elhs, op, erhs))
+                raise SyntaxError('invalid comparison: %s %s %s' %
+                                  (elhs, op, erhs))
 
             lhs = self.evaluate(elhs, context)
             rhs = self.evaluate(erhs, context)
-            if ((elhs == 'python_version' or erhs == 'python_version') and
-                op in ('<', '<=', '>', '>=', '===', '==', '!=', '~=')):
-                lhs = NV(lhs)
-                rhs = NV(rhs)
-            elif elhs == 'python_version' and op in ('in', 'not in'):
-                lhs = NV(lhs)
+            if ((_is_version_marker(elhs) or _is_version_marker(erhs))
+                    and op in ('<', '<=', '>', '>=', '===', '==', '!=', '~=')):
+                lhs = LV(lhs)
+                rhs = LV(rhs)
+            elif _is_version_marker(elhs) and op in ('in', 'not in'):
+                lhs = LV(lhs)
                 rhs = _get_versions(rhs)
             result = self.operations[op](lhs, rhs)
         return result
 
+
 _DIGITS = re.compile(r'\d+\.\d+')
 
+
 def default_context():
+
     def format_full_version(info):
         version = '%s.%s.%s' % (info.major, info.minor, info.micro)
         kind = info.releaselevel
@@ -101,7 +111,8 @@
         return version
 
     if hasattr(sys, 'implementation'):
-        implementation_version = format_full_version(sys.implementation.version)
+        implementation_version = format_full_version(
+            sys.implementation.version)
         implementation_name = sys.implementation.name
     else:
         implementation_version = '0'
@@ -126,11 +137,13 @@
     }
     return result
 
+
 DEFAULT_CONTEXT = default_context()
 del default_context
 
 evaluator = Evaluator()
 
+
 def interpret(marker, execution_context=None):
     """
     Interpret a marker and return a result depending on environment.
@@ -143,9 +156,11 @@
     try:
         expr, rest = parse_marker(marker)
     except Exception as e:
-        raise SyntaxError('Unable to interpret marker syntax: %s: %s' % (marker, e))
+        raise SyntaxError('Unable to interpret marker syntax: %s: %s' %
+                          (marker, e))
     if rest and rest[0] != '#':
-        raise SyntaxError('unexpected trailing data in marker: %s: %s' % (marker, rest))
+        raise SyntaxError('unexpected trailing data in marker: %s: %s' %
+                          (marker, rest))
     context = dict(DEFAULT_CONTEXT)
     if execution_context:
         context.update(execution_context)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/metadata.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/metadata.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/metadata.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/metadata.py	2024-02-03 17:39:20.063082493 -0500
@@ -136,17 +136,9 @@
 def _best_version(fields):
     """Detect the best version depending on the fields used."""
     def _has_marker(keys, markers):
-        for marker in markers:
-            if marker in keys:
-                return True
-        return False
-
-    keys = []
-    for key, value in fields.items():
-        if value in ([], 'UNKNOWN', None):
-            continue
-        keys.append(key)
+        return any(marker in keys for marker in markers)
 
+    keys = [key for key, value in fields.items() if value not in ([], 'UNKNOWN', None)]
     possible_versions = ['1.0', '1.1', '1.2', '1.3', '2.1', '2.2']  # 2.0 removed
 
     # first let's try to see if a field is not part of one of the version
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/scripts.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/scripts.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/scripts.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/scripts.py	2024-02-03 17:39:20.063082493 -0500
@@ -1,6 +1,6 @@
 # -*- coding: utf-8 -*-
 #
-# Copyright (C) 2013-2015 Vinay Sajip.
+# Copyright (C) 2013-2023 Vinay Sajip.
 # Licensed to the Python Software Foundation under a contributor agreement.
 # See LICENSE.txt and CONTRIBUTORS.txt.
 #
@@ -65,9 +65,11 @@
                 executable = '"%s"' % executable
     return executable
 
+
 # Keep the old name around (for now), as there is at least one project using it!
 _enquote_executable = enquote_executable
 
+
 class ScriptMaker(object):
     """
     A class to copy or create scripts from source scripts or callable
@@ -77,21 +79,25 @@
 
     executable = None  # for shebangs
 
-    def __init__(self, source_dir, target_dir, add_launchers=True,
-                 dry_run=False, fileop=None):
+    def __init__(self,
+                 source_dir,
+                 target_dir,
+                 add_launchers=True,
+                 dry_run=False,
+                 fileop=None):
         self.source_dir = source_dir
         self.target_dir = target_dir
         self.add_launchers = add_launchers
         self.force = False
         self.clobber = False
         # It only makes sense to set mode bits on POSIX.
-        self.set_mode = (os.name == 'posix') or (os.name == 'java' and
-                                                 os._name == 'posix')
+        self.set_mode = (os.name == 'posix') or (os.name == 'java'
+                                                 and os._name == 'posix')
         self.variants = set(('', 'X.Y'))
         self._fileop = fileop or FileOperator(dry_run)
 
-        self._is_nt = os.name == 'nt' or (
-            os.name == 'java' and os._name == 'nt')
+        self._is_nt = os.name == 'nt' or (os.name == 'java'
+                                          and os._name == 'nt')
         self.version_info = sys.version_info
 
     def _get_alternate_executable(self, executable, options):
@@ -102,6 +108,7 @@
         return executable
 
     if sys.platform.startswith('java'):  # pragma: no cover
+
         def _is_shell(self, executable):
             """
             Determine if the specified executable is a script
@@ -146,8 +153,8 @@
                 max_shebang_length = 512
             else:
                 max_shebang_length = 127
-            simple_shebang = ((b' ' not in executable) and
-                              (shebang_length <= max_shebang_length))
+            simple_shebang = ((b' ' not in executable)
+                              and (shebang_length <= max_shebang_length))
 
         if simple_shebang:
             result = b'#!' + executable + post_interp + b'\n'
@@ -161,22 +168,25 @@
         enquote = True
         if self.executable:
             executable = self.executable
-            enquote = False     # assume this will be taken care of
+            enquote = False  # assume this will be taken care of
         elif not sysconfig.is_python_build():
             executable = get_executable()
         elif in_venv():  # pragma: no cover
-            executable = os.path.join(sysconfig.get_path('scripts'),
-                            'python%s' % sysconfig.get_config_var('EXE'))
-        else:  # pragma: no cover
             executable = os.path.join(
-                sysconfig.get_config_var('BINDIR'),
-               'python%s%s' % (sysconfig.get_config_var('VERSION'),
-                               sysconfig.get_config_var('EXE')))
-            if not os.path.isfile(executable):
+                sysconfig.get_path('scripts'),
+                'python%s' % sysconfig.get_config_var('EXE'))
+        else:  # pragma: no cover
+            if os.name == 'nt':
                 # for Python builds from source on Windows, no Python executables with
                 # a version suffix are created, so we use python.exe
-                executable = os.path.join(sysconfig.get_config_var('BINDIR'),
-                                'python%s' % (sysconfig.get_config_var('EXE')))
+                executable = os.path.join(
+                    sysconfig.get_config_var('BINDIR'),
+                    'python%s' % (sysconfig.get_config_var('EXE')))
+            else:
+                executable = os.path.join(
+                    sysconfig.get_config_var('BINDIR'),
+                    'python%s%s' % (sysconfig.get_config_var('VERSION'),
+                                    sysconfig.get_config_var('EXE')))
         if options:
             executable = self._get_alternate_executable(executable, options)
 
@@ -201,7 +211,7 @@
         executable = executable.encode('utf-8')
         # in case of IronPython, play safe and enable frames support
         if (sys.platform == 'cli' and '-X:Frames' not in post_interp
-            and '-X:FullFrames' not in post_interp):  # pragma: no cover
+                and '-X:FullFrames' not in post_interp):  # pragma: no cover
             post_interp += b' -X:Frames'
         shebang = self._build_shebang(executable, post_interp)
         # Python parser starts to read a script using UTF-8 until
@@ -212,8 +222,8 @@
         try:
             shebang.decode('utf-8')
         except UnicodeDecodeError:  # pragma: no cover
-            raise ValueError(
-                'The shebang (%r) is not decodable from utf-8' % shebang)
+            raise ValueError('The shebang (%r) is not decodable from utf-8' %
+                             shebang)
         # If the script is encoded to a custom encoding (use a
         # #coding:xxx cookie), the shebang has to be decodable from
         # the script encoding too.
@@ -221,15 +231,16 @@
             try:
                 shebang.decode(encoding)
             except UnicodeDecodeError:  # pragma: no cover
-                raise ValueError(
-                    'The shebang (%r) is not decodable '
-                    'from the script encoding (%r)' % (shebang, encoding))
+                raise ValueError('The shebang (%r) is not decodable '
+                                 'from the script encoding (%r)' %
+                                 (shebang, encoding))
         return shebang
 
     def _get_script_text(self, entry):
-        return self.script_template % dict(module=entry.prefix,
-                                           import_name=entry.suffix.split('.')[0],
-                                           func=entry.suffix)
+        return self.script_template % dict(
+            module=entry.prefix,
+            import_name=entry.suffix.split('.')[0],
+            func=entry.suffix)
 
     manifest = _DEFAULT_MANIFEST
 
@@ -254,7 +265,8 @@
                 source_date_epoch = os.environ.get('SOURCE_DATE_EPOCH')
                 if source_date_epoch:
                     date_time = time.gmtime(int(source_date_epoch))[:6]
-                    zinfo = ZipInfo(filename='__main__.py', date_time=date_time)
+                    zinfo = ZipInfo(filename='__main__.py',
+                                    date_time=date_time)
                     zf.writestr(zinfo, script_bytes)
                 else:
                     zf.writestr('__main__.py', script_bytes)
@@ -275,7 +287,7 @@
                                    'use .deleteme logic')
                     dfname = '%s.deleteme' % outname
                     if os.path.exists(dfname):
-                        os.remove(dfname)       # Not allowed to fail here
+                        os.remove(dfname)  # Not allowed to fail here
                     os.rename(outname, dfname)  # nor here
                     self._fileop.write_binary_file(outname, script_bytes)
                     logger.debug('Able to replace executable using '
@@ -283,9 +295,10 @@
                     try:
                         os.remove(dfname)
                     except Exception:
-                        pass    # still in use - ignore error
+                        pass  # still in use - ignore error
             else:
-                if self._is_nt and not outname.endswith('.' + ext):  # pragma: no cover
+                if self._is_nt and not outname.endswith(
+                        '.' + ext):  # pragma: no cover
                     outname = '%s.%s' % (outname, ext)
                 if os.path.exists(outname) and not self.clobber:
                     logger.warning('Skipping existing file %s', outname)
@@ -304,8 +317,9 @@
         if 'X' in self.variants:
             result.add('%s%s' % (name, self.version_info[0]))
         if 'X.Y' in self.variants:
-            result.add('%s%s%s.%s' % (name, self.variant_separator,
-                                      self.version_info[0], self.version_info[1]))
+            result.add('%s%s%s.%s' %
+                       (name, self.variant_separator, self.version_info[0],
+                        self.version_info[1]))
         return result
 
     def _make_script(self, entry, filenames, options=None):
@@ -383,12 +397,13 @@
     def dry_run(self, value):
         self._fileop.dry_run = value
 
-    if os.name == 'nt' or (os.name == 'java' and os._name == 'nt'):  # pragma: no cover
+    if os.name == 'nt' or (os.name == 'java'
+                           and os._name == 'nt'):  # pragma: no cover
         # Executable launcher support.
         # Launchers are from https://bitbucket.org/vinay.sajip/simple_launcher/
 
         def _get_launcher(self, kind):
-            if struct.calcsize('P') == 8:   # 64-bit
+            if struct.calcsize('P') == 8:  # 64-bit
                 bits = '64'
             else:
                 bits = '32'
@@ -399,8 +414,8 @@
             distlib_package = __name__.rsplit('.', 1)[0]
             resource = finder(distlib_package).find(name)
             if not resource:
-                msg = ('Unable to find resource %s in package %s' % (name,
-                       distlib_package))
+                msg = ('Unable to find resource %s in package %s' %
+                       (name, distlib_package))
                 raise ValueError(msg)
             return resource.bytes
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/util.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/util.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/util.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/util.py	2024-02-03 17:39:20.063082493 -0500
@@ -1,5 +1,5 @@
 #
-# Copyright (C) 2012-2021 The Python Software Foundation.
+# Copyright (C) 2012-2023 The Python Software Foundation.
 # See LICENSE.txt and CONTRIBUTORS.txt.
 #
 import codecs
@@ -33,7 +33,7 @@
 from . import DistlibException
 from .compat import (string_types, text_type, shutil, raw_input, StringIO,
                      cache_from_source, urlopen, urljoin, httplib, xmlrpclib,
-                     splittype, HTTPHandler, BaseConfigurator, valid_ident,
+                     HTTPHandler, BaseConfigurator, valid_ident,
                      Container, configparser, URLError, ZipFile, fsdecode,
                      unquote, urlparse)
 
@@ -62,6 +62,7 @@
     interpreted as a literal string, and a string not contained in quotes is a
     variable (such as os_name).
     """
+
     def marker_var(remaining):
         # either identifier, or literal string
         m = IDENTIFIER.match(remaining)
@@ -87,7 +88,8 @@
                 else:
                     m = STRING_CHUNK.match(remaining)
                     if not m:
-                        raise SyntaxError('error in string literal: %s' % remaining)
+                        raise SyntaxError('error in string literal: %s' %
+                                          remaining)
                     parts.append(m.groups()[0])
                     remaining = remaining[m.end():]
             else:
@@ -95,7 +97,7 @@
                 raise SyntaxError('unterminated string: %s' % s)
             parts.append(q)
             result = ''.join(parts)
-            remaining = remaining[1:].lstrip() # skip past closing quote
+            remaining = remaining[1:].lstrip()  # skip past closing quote
         return result, remaining
 
     def marker_expr(remaining):
@@ -208,7 +210,8 @@
                         ver_remaining = ver_remaining[m.end():]
                         m = VERSION_IDENTIFIER.match(ver_remaining)
                         if not m:
-                            raise SyntaxError('invalid version: %s' % ver_remaining)
+                            raise SyntaxError('invalid version: %s' %
+                                              ver_remaining)
                         v = m.groups()[0]
                         versions.append((op, v))
                         ver_remaining = ver_remaining[m.end():]
@@ -221,7 +224,8 @@
                             break
                         m = COMPARE_OP.match(ver_remaining)
                         if not m:
-                            raise SyntaxError('invalid constraint: %s' % ver_remaining)
+                            raise SyntaxError('invalid constraint: %s' %
+                                              ver_remaining)
                     if not versions:
                         versions = None
                 return versions, ver_remaining
@@ -231,7 +235,8 @@
             else:
                 i = remaining.find(')', 1)
                 if i < 0:
-                    raise SyntaxError('unterminated parenthesis: %s' % remaining)
+                    raise SyntaxError('unterminated parenthesis: %s' %
+                                      remaining)
                 s = remaining[1:i]
                 remaining = remaining[i + 1:].lstrip()
                 # As a special diversion from PEP 508, allow a version number
@@ -262,9 +267,14 @@
     if not versions:
         rs = distname
     else:
-        rs = '%s %s' % (distname, ', '.join(['%s %s' % con for con in versions]))
-    return Container(name=distname, extras=extras, constraints=versions,
-                     marker=mark_expr, url=uri, requirement=rs)
+        rs = '%s %s' % (distname, ', '.join(
+            ['%s %s' % con for con in versions]))
+    return Container(name=distname,
+                     extras=extras,
+                     constraints=versions,
+                     marker=mark_expr,
+                     url=uri,
+                     requirement=rs)
 
 
 def get_resources_dests(resources_root, rules):
@@ -304,15 +314,15 @@
 
 
 def get_executable():
-# The __PYVENV_LAUNCHER__ dance is apparently no longer needed, as
-# changes to the stub launcher mean that sys.executable always points
-# to the stub on OS X
-#    if sys.platform == 'darwin' and ('__PYVENV_LAUNCHER__'
-#                                     in os.environ):
-#        result =  os.environ['__PYVENV_LAUNCHER__']
-#    else:
-#        result = sys.executable
-#    return result
+    # The __PYVENV_LAUNCHER__ dance is apparently no longer needed, as
+    # changes to the stub launcher mean that sys.executable always points
+    # to the stub on OS X
+    #    if sys.platform == 'darwin' and ('__PYVENV_LAUNCHER__'
+    #                                     in os.environ):
+    #        result =  os.environ['__PYVENV_LAUNCHER__']
+    #    else:
+    #        result = sys.executable
+    #    return result
     # Avoid normcasing: see issue #143
     # result = os.path.normcase(sys.executable)
     result = sys.executable
@@ -346,6 +356,7 @@
             result[key] = d[key]
     return result
 
+
 def read_exports(stream):
     if sys.version_info[0] >= 3:
         # needs to be a text stream
@@ -388,7 +399,7 @@
             s = '%s = %s' % (name, value)
             entry = get_export_entry(s)
             assert entry is not None
-            #entry.dist = self
+            # entry.dist = self
             entries[name] = entry
     return result
 
@@ -420,6 +431,7 @@
     finally:
         shutil.rmtree(td)
 
+
 @contextlib.contextmanager
 def chdir(d):
     cwd = os.getcwd()
@@ -441,19 +453,21 @@
 
 
 class cached_property(object):
+
     def __init__(self, func):
         self.func = func
-        #for attr in ('__name__', '__module__', '__doc__'):
-        #    setattr(self, attr, getattr(func, attr, None))
+        # for attr in ('__name__', '__module__', '__doc__'):
+        #     setattr(self, attr, getattr(func, attr, None))
 
     def __get__(self, obj, cls=None):
         if obj is None:
             return self
         value = self.func(obj)
         object.__setattr__(obj, self.func.__name__, value)
-        #obj.__dict__[self.func.__name__] = value = self.func(obj)
+        # obj.__dict__[self.func.__name__] = value = self.func(obj)
         return value
 
+
 def convert_path(pathname):
     """Return 'pathname' as a name that will work on the native filesystem.
 
@@ -482,6 +496,7 @@
 
 
 class FileOperator(object):
+
     def __init__(self, dry_run=False):
         self.dry_run = dry_run
         self.ensured = set()
@@ -586,7 +601,12 @@
             if self.record:
                 self.dirs_created.add(path)
 
-    def byte_compile(self, path, optimize=False, force=False, prefix=None, hashed_invalidation=False):
+    def byte_compile(self,
+                     path,
+                     optimize=False,
+                     force=False,
+                     prefix=None,
+                     hashed_invalidation=False):
         dpath = cache_from_source(path, not optimize)
         logger.info('Byte-compiling %s to %s', path, dpath)
         if not self.dry_run:
@@ -597,9 +617,12 @@
                     assert path.startswith(prefix)
                     diagpath = path[len(prefix):]
             compile_kwargs = {}
-            if hashed_invalidation and hasattr(py_compile, 'PycInvalidationMode'):
-                compile_kwargs['invalidation_mode'] = py_compile.PycInvalidationMode.CHECKED_HASH
-            py_compile.compile(path, dpath, diagpath, True, **compile_kwargs)     # raise error
+            if hashed_invalidation and hasattr(py_compile,
+                                               'PycInvalidationMode'):
+                compile_kwargs[
+                    'invalidation_mode'] = py_compile.PycInvalidationMode.CHECKED_HASH
+            py_compile.compile(path, dpath, diagpath, True,
+                               **compile_kwargs)  # raise error
         self.record_as_written(dpath)
         return dpath
 
@@ -661,9 +684,10 @@
                     assert flist == ['__pycache__']
                     sd = os.path.join(d, flist[0])
                     os.rmdir(sd)
-                os.rmdir(d)     # should fail if non-empty
+                os.rmdir(d)  # should fail if non-empty
         self._init_record()
 
+
 def resolve(module_name, dotted_path):
     if module_name in sys.modules:
         mod = sys.modules[module_name]
@@ -680,6 +704,7 @@
 
 
 class ExportEntry(object):
+
     def __init__(self, name, prefix, suffix, flags):
         self.name = name
         self.prefix = prefix
@@ -698,20 +723,21 @@
         if not isinstance(other, ExportEntry):
             result = False
         else:
-            result = (self.name == other.name and
-                      self.prefix == other.prefix and
-                      self.suffix == other.suffix and
-                      self.flags == other.flags)
+            result = (self.name == other.name and self.prefix == other.prefix
+                      and self.suffix == other.suffix
+                      and self.flags == other.flags)
         return result
 
     __hash__ = object.__hash__
 
 
-ENTRY_RE = re.compile(r'''(?P<name>(\w|[-.+])+)
+ENTRY_RE = re.compile(
+    r'''(?P<name>([^\[]\S*))
                       \s*=\s*(?P<callable>(\w+)([:\.]\w+)*)
                       \s*(\[\s*(?P<flags>[\w-]+(=\w+)?(,\s*\w+(=\w+)?)*)\s*\])?
                       ''', re.VERBOSE)
 
+
 def get_export_entry(specification):
     m = ENTRY_RE.search(specification)
     if not m:
@@ -827,6 +853,7 @@
     os.umask(result)
     return result
 
+
 def is_string_sequence(seq):
     result = True
     i = None
@@ -837,8 +864,10 @@
     assert i is not None
     return result
 
-PROJECT_NAME_AND_VERSION = re.compile('([a-z0-9_]+([.-][a-z_][a-z0-9_]*)*)-'
-                                      '([a-z0-9_.+-]+)', re.I)
+
+PROJECT_NAME_AND_VERSION = re.compile(
+    '([a-z0-9_]+([.-][a-z_][a-z0-9_]*)*)-'
+    '([a-z0-9_.+-]+)', re.I)
 PYTHON_VERSION = re.compile(r'-py(\d\.?\d?)')
 
 
@@ -866,10 +895,12 @@
             result = m.group(1), m.group(3), pyver
     return result
 
+
 # Allow spaces in name because of legacy dists like "Twisted Core"
 NAME_VERSION_RE = re.compile(r'(?P<name>[\w .-]+)\s*'
                              r'\(\s*(?P<ver>[^\s)]+)\)$')
 
+
 def parse_name_and_version(p):
     """
     A utility method used to get name and version from a string.
@@ -885,6 +916,7 @@
     d = m.groupdict()
     return d['name'].strip().lower(), d['ver']
 
+
 def get_extras(requested, available):
     result = set()
     requested = set(requested or [])
@@ -906,10 +938,13 @@
                 logger.warning('undeclared extra: %s' % r)
             result.add(r)
     return result
+
+
 #
 # Extended metadata functionality
 #
 
+
 def _get_external_data(url):
     result = {}
     try:
@@ -923,21 +958,24 @@
             logger.debug('Unexpected response for JSON request: %s', ct)
         else:
             reader = codecs.getreader('utf-8')(resp)
-            #data = reader.read().decode('utf-8')
-            #result = json.loads(data)
+            # data = reader.read().decode('utf-8')
+            # result = json.loads(data)
             result = json.load(reader)
     except Exception as e:
         logger.exception('Failed to get external data for %s: %s', url, e)
     return result
 
+
 _external_data_base_url = 'https://www.red-dove.com/pypi/projects/'
 
+
 def get_project_data(name):
     url = '%s/%s/project.json' % (name[0].upper(), name)
     url = urljoin(_external_data_base_url, url)
     result = _get_external_data(url)
     return result
 
+
 def get_package_data(name, version):
     url = '%s/%s/package-%s.json' % (name[0].upper(), name, version)
     url = urljoin(_external_data_base_url, url)
@@ -992,6 +1030,7 @@
     """
     A very simple publish/subscribe system.
     """
+
     def __init__(self):
         self._subscribers = {}
 
@@ -1053,18 +1092,20 @@
                 logger.exception('Exception during event publication')
                 value = None
             result.append(value)
-        logger.debug('publish %s: args = %s, kwargs = %s, result = %s',
-                     event, args, kwargs, result)
+        logger.debug('publish %s: args = %s, kwargs = %s, result = %s', event,
+                     args, kwargs, result)
         return result
 
+
 #
 # Simple sequencing
 #
 class Sequencer(object):
+
     def __init__(self):
         self._preds = {}
         self._succs = {}
-        self._nodes = set()     # nodes with no preds/succs
+        self._nodes = set()  # nodes with no preds/succs
 
     def add_node(self, node):
         self._nodes.add(node)
@@ -1104,8 +1145,8 @@
             raise ValueError('%r not a successor of %r' % (succ, pred))
 
     def is_step(self, step):
-        return (step in self._preds or step in self._succs or
-                step in self._nodes)
+        return (step in self._preds or step in self._succs
+                or step in self._nodes)
 
     def get_steps(self, final):
         if not self.is_step(final):
@@ -1134,7 +1175,7 @@
 
     @property
     def strong_connections(self):
-        #http://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm
+        # http://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm
         index_counter = [0]
         stack = []
         lowlinks = {}
@@ -1159,11 +1200,11 @@
                 if successor not in lowlinks:
                     # Successor has not yet been visited
                     strongconnect(successor)
-                    lowlinks[node] = min(lowlinks[node],lowlinks[successor])
+                    lowlinks[node] = min(lowlinks[node], lowlinks[successor])
                 elif successor in stack:
                     # the successor is in the stack and hence in the current
                     # strongly connected component (SCC)
-                    lowlinks[node] = min(lowlinks[node],index[successor])
+                    lowlinks[node] = min(lowlinks[node], index[successor])
 
             # If `node` is a root node, pop the stack and generate an SCC
             if lowlinks[node] == index[node]:
@@ -1172,7 +1213,8 @@
                 while True:
                     successor = stack.pop()
                     connected_component.append(successor)
-                    if successor == node: break
+                    if successor == node:
+                        break
                 component = tuple(connected_component)
                 # storing the result
                 result.append(component)
@@ -1195,12 +1237,14 @@
         result.append('}')
         return '\n'.join(result)
 
+
 #
 # Unarchiving functionality for zip, tar, tgz, tbz, whl
 #
 
-ARCHIVE_EXTENSIONS = ('.tar.gz', '.tar.bz2', '.tar', '.zip',
-                      '.tgz', '.tbz', '.whl')
+ARCHIVE_EXTENSIONS = ('.tar.gz', '.tar.bz2', '.tar', '.zip', '.tgz', '.tbz',
+                      '.whl')
+
 
 def unarchive(archive_filename, dest_dir, format=None, check=True):
 
@@ -1249,6 +1293,20 @@
             for tarinfo in archive.getmembers():
                 if not isinstance(tarinfo.name, text_type):
                     tarinfo.name = tarinfo.name.decode('utf-8')
+
+        # Limit extraction of dangerous items, if this Python
+        # allows it easily. If not, just trust the input.
+        # See: https://docs.python.org/3/library/tarfile.html#extraction-filters
+        def extraction_filter(member, path):
+            """Run tarfile.tar_filter, but raise the expected ValueError"""
+            # This is only called if the current Python has tarfile filters
+            try:
+                return tarfile.tar_filter(member, path)
+            except tarfile.FilterError as exc:
+                raise ValueError(str(exc))
+
+        archive.extraction_filter = extraction_filter
+
         archive.extractall(dest_dir)
 
     finally:
@@ -1269,11 +1327,12 @@
                 zf.write(full, dest)
     return result
 
+
 #
 # Simple progress bar
 #
 
-UNITS = ('', 'K', 'M', 'G','T','P')
+UNITS = ('', 'K', 'M', 'G', 'T', 'P')
 
 
 class Progress(object):
@@ -1328,8 +1387,8 @@
     def format_duration(self, duration):
         if (duration <= 0) and self.max is None or self.cur == self.min:
             result = '??:??:??'
-        #elif duration < 1:
-        #    result = '--:--:--'
+        # elif duration < 1:
+        #     result = '--:--:--'
         else:
             result = time.strftime('%H:%M:%S', time.gmtime(duration))
         return result
@@ -1339,7 +1398,7 @@
         if self.done:
             prefix = 'Done'
             t = self.elapsed
-            #import pdb; pdb.set_trace()
+            # import pdb; pdb.set_trace()
         else:
             prefix = 'ETA '
             if self.max is None:
@@ -1347,7 +1406,7 @@
             elif self.elapsed == 0 or (self.cur == self.min):
                 t = 0
             else:
-                #import pdb; pdb.set_trace()
+                # import pdb; pdb.set_trace()
                 t = float(self.max - self.min)
                 t /= self.cur - self.min
                 t = (t - 1) * self.elapsed
@@ -1365,6 +1424,7 @@
             result /= 1000.0
         return '%d %sB/s' % (result, unit)
 
+
 #
 # Glob functionality
 #
@@ -1412,22 +1472,23 @@
                 for fn in _iglob(os.path.join(path, radical)):
                     yield fn
 
+
 if ssl:
     from .compat import (HTTPSHandler as BaseHTTPSHandler, match_hostname,
                          CertificateError)
 
-
-#
-# HTTPSConnection which verifies certificates/matches domains
-#
+    #
+    # HTTPSConnection which verifies certificates/matches domains
+    #
 
     class HTTPSConnection(httplib.HTTPSConnection):
-        ca_certs = None # set this to the path to the certs file (.pem)
-        check_domain = True # only used if ca_certs is not None
+        ca_certs = None  # set this to the path to the certs file (.pem)
+        check_domain = True  # only used if ca_certs is not None
 
         # noinspection PyPropertyAccess
         def connect(self):
-            sock = socket.create_connection((self.host, self.port), self.timeout)
+            sock = socket.create_connection((self.host, self.port),
+                                            self.timeout)
             if getattr(self, '_tunnel_host', False):
                 self.sock = sock
                 self._tunnel()
@@ -1435,7 +1496,7 @@
             context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
             if hasattr(ssl, 'OP_NO_SSLv2'):
                 context.options |= ssl.OP_NO_SSLv2
-            if self.cert_file:
+            if getattr(self, 'cert_file', None):
                 context.load_cert_chain(self.cert_file, self.key_file)
             kwargs = {}
             if self.ca_certs:
@@ -1455,6 +1516,7 @@
                     raise
 
     class HTTPSHandler(BaseHTTPSHandler):
+
         def __init__(self, ca_certs, check_domain=True):
             BaseHTTPSHandler.__init__(self)
             self.ca_certs = ca_certs
@@ -1481,8 +1543,9 @@
                 return self.do_open(self._conn_maker, req)
             except URLError as e:
                 if 'certificate verify failed' in str(e.reason):
-                    raise CertificateError('Unable to verify server certificate '
-                                           'for %s' % req.host)
+                    raise CertificateError(
+                        'Unable to verify server certificate '
+                        'for %s' % req.host)
                 else:
                     raise
 
@@ -1496,14 +1559,18 @@
     # handler for HTTP itself.
     #
     class HTTPSOnlyHandler(HTTPSHandler, HTTPHandler):
+
         def http_open(self, req):
-            raise URLError('Unexpected HTTP request on what should be a secure '
-                           'connection: %s' % req)
+            raise URLError(
+                'Unexpected HTTP request on what should be a secure '
+                'connection: %s' % req)
+
 
 #
 # XML-RPC with timeouts
 #
 class Transport(xmlrpclib.Transport):
+
     def __init__(self, timeout, use_datetime=0):
         self.timeout = timeout
         xmlrpclib.Transport.__init__(self, use_datetime)
@@ -1515,8 +1582,11 @@
             self._connection = host, httplib.HTTPConnection(h)
         return self._connection[1]
 
+
 if ssl:
+
     class SafeTransport(xmlrpclib.SafeTransport):
+
         def __init__(self, timeout, use_datetime=0):
             self.timeout = timeout
             xmlrpclib.SafeTransport.__init__(self, use_datetime)
@@ -1528,12 +1598,13 @@
             kwargs['timeout'] = self.timeout
             if not self._connection or host != self._connection[0]:
                 self._extra_headers = eh
-                self._connection = host, httplib.HTTPSConnection(h, None,
-                                                                 **kwargs)
+                self._connection = host, httplib.HTTPSConnection(
+                    h, None, **kwargs)
             return self._connection[1]
 
 
 class ServerProxy(xmlrpclib.ServerProxy):
+
     def __init__(self, uri, **kwargs):
         self.timeout = timeout = kwargs.pop('timeout', None)
         # The above classes only come into play if a timeout
@@ -1550,11 +1621,13 @@
             self.transport = t
         xmlrpclib.ServerProxy.__init__(self, uri, **kwargs)
 
+
 #
 # CSV functionality. This is provided because on 2.x, the csv module can't
 # handle Unicode. However, we need to deal with Unicode in e.g. RECORD files.
 #
 
+
 def _csv_open(fn, mode, **kwargs):
     if sys.version_info[0] < 3:
         mode += 'b'
@@ -1568,9 +1641,9 @@
 
 class CSVBase(object):
     defaults = {
-        'delimiter': str(','),      # The strs are used because we need native
-        'quotechar': str('"'),      # str in the csv API (2.x won't take
-        'lineterminator': str('\n') # Unicode)
+        'delimiter': str(','),  # The strs are used because we need native
+        'quotechar': str('"'),  # str in the csv API (2.x won't take
+        'lineterminator': str('\n')  # Unicode)
     }
 
     def __enter__(self):
@@ -1581,6 +1654,7 @@
 
 
 class CSVReader(CSVBase):
+
     def __init__(self, **kwargs):
         if 'stream' in kwargs:
             stream = kwargs['stream']
@@ -1605,7 +1679,9 @@
 
     __next__ = next
 
+
 class CSVWriter(CSVBase):
+
     def __init__(self, fn, **kwargs):
         self.stream = _csv_open(fn, 'w')
         self.writer = csv.writer(self.stream, **self.defaults)
@@ -1620,10 +1696,12 @@
             row = r
         self.writer.writerow(row)
 
+
 #
 #   Configurator functionality
 #
 
+
 class Configurator(BaseConfigurator):
 
     value_converters = dict(BaseConfigurator.value_converters)
@@ -1634,6 +1712,7 @@
         self.base = base or os.getcwd()
 
     def configure_custom(self, config):
+
         def convert(o):
             if isinstance(o, (list, tuple)):
                 result = type(o)([convert(i) for i in o])
@@ -1683,6 +1762,7 @@
     """
     Mixin for running subprocesses and capturing their output
     """
+
     def __init__(self, verbose=False, progress=None):
         self.verbose = verbose
         self.progress = progress
@@ -1709,8 +1789,10 @@
         stream.close()
 
     def run_command(self, cmd, **kwargs):
-        p = subprocess.Popen(cmd, stdout=subprocess.PIPE,
-                             stderr=subprocess.PIPE, **kwargs)
+        p = subprocess.Popen(cmd,
+                             stdout=subprocess.PIPE,
+                             stderr=subprocess.PIPE,
+                             **kwargs)
         t1 = threading.Thread(target=self.reader, args=(p.stdout, 'stdout'))
         t1.start()
         t2 = threading.Thread(target=self.reader, args=(p.stderr, 'stderr'))
@@ -1730,15 +1812,17 @@
     # https://www.python.org/dev/peps/pep-0503/#normalized-names
     return re.sub('[-_.]+', '-', name).lower()
 
+
 # def _get_pypirc_command():
-    # """
-    # Get the distutils command for interacting with PyPI configurations.
-    # :return: the command.
-    # """
-    # from distutils.core import Distribution
-    # from distutils.config import PyPIRCCommand
-    # d = Distribution()
-    # return PyPIRCCommand(d)
+# """
+# Get the distutils command for interacting with PyPI configurations.
+# :return: the command.
+# """
+# from distutils.core import Distribution
+# from distutils.config import PyPIRCCommand
+# d = Distribution()
+# return PyPIRCCommand(d)
+
 
 class PyPIRCFile(object):
 
@@ -1763,9 +1847,10 @@
             if 'distutils' in sections:
                 # let's get the list of servers
                 index_servers = config.get('distutils', 'index-servers')
-                _servers = [server.strip() for server in
-                            index_servers.split('\n')
-                            if server.strip() != '']
+                _servers = [
+                    server.strip() for server in index_servers.split('\n')
+                    if server.strip() != ''
+                ]
                 if _servers == []:
                     # nothing set, let's try to get the default pypi
                     if 'pypi' in sections:
@@ -1776,7 +1861,8 @@
                         result['username'] = config.get(server, 'username')
 
                         # optional params
-                        for key, default in (('repository', self.DEFAULT_REPOSITORY),
+                        for key, default in (('repository',
+                                              self.DEFAULT_REPOSITORY),
                                              ('realm', self.DEFAULT_REALM),
                                              ('password', None)):
                             if config.has_option(server, key):
@@ -1787,11 +1873,11 @@
                         # work around people having "repository" for the "pypi"
                         # section of their config set to the HTTP (rather than
                         # HTTPS) URL
-                        if (server == 'pypi' and
-                            repository in (self.DEFAULT_REPOSITORY, 'pypi')):
+                        if (server == 'pypi' and repository
+                                in (self.DEFAULT_REPOSITORY, 'pypi')):
                             result['repository'] = self.DEFAULT_REPOSITORY
-                        elif (result['server'] != repository and
-                              result['repository'] != repository):
+                        elif (result['server'] != repository
+                              and result['repository'] != repository):
                             result = {}
             elif 'server-login' in sections:
                 # old format
@@ -1821,20 +1907,24 @@
         with open(fn, 'w') as f:
             config.write(f)
 
+
 def _load_pypirc(index):
     """
     Read the PyPI access configuration as supported by distutils.
     """
     return PyPIRCFile(url=index.url).read()
 
+
 def _store_pypirc(index):
     PyPIRCFile().update(index.username, index.password)
 
+
 #
 # get_platform()/get_host_platform() copied from Python 3.10.a0 source, with some minor
 # tweaks
 #
 
+
 def get_host_platform():
     """Return a string that identifies the current platform.  This is used mainly to
     distinguish platform-specific build directories and platform-specific built
@@ -1886,16 +1976,16 @@
         # At least on Linux/Intel, 'machine' is the processor --
         # i386, etc.
         # XXX what about Alpha, SPARC, etc?
-        return  "%s-%s" % (osname, machine)
+        return "%s-%s" % (osname, machine)
 
     elif osname[:5] == 'sunos':
-        if release[0] >= '5':           # SunOS 5 == Solaris 2
+        if release[0] >= '5':  # SunOS 5 == Solaris 2
             osname = 'solaris'
             release = '%d.%s' % (int(release[0]) - 3, release[2:])
             # We can't use 'platform.architecture()[0]' because a
             # bootstrap problem. We use a dict to get an error
             # if some suspicious happens.
-            bitness = {2147483647:'32bit', 9223372036854775807:'64bit'}
+            bitness = {2147483647: '32bit', 9223372036854775807: '64bit'}
             machine += '.%s' % bitness[sys.maxsize]
         # fall through to standard osname-release-machine representation
     elif osname[:3] == 'aix':
@@ -1903,23 +1993,26 @@
         return aix_platform()
     elif osname[:6] == 'cygwin':
         osname = 'cygwin'
-        rel_re = re.compile (r'[\d.]+', re.ASCII)
+        rel_re = re.compile(r'[\d.]+', re.ASCII)
         m = rel_re.match(release)
         if m:
             release = m.group()
     elif osname[:6] == 'darwin':
-        import _osx_support, distutils.sysconfig
+        import _osx_support
+        try:
+            from distutils import sysconfig
+        except ImportError:
+            import sysconfig
         osname, release, machine = _osx_support.get_platform_osx(
-                                        distutils.sysconfig.get_config_vars(),
-                                        osname, release, machine)
+            sysconfig.get_config_vars(), osname, release, machine)
 
     return '%s-%s-%s' % (osname, release, machine)
 
 
 _TARGET_TO_PLAT = {
-    'x86' : 'win32',
-    'x64' : 'win-amd64',
-    'arm' : 'win-arm32',
+    'x86': 'win32',
+    'x64': 'win-amd64',
+    'arm': 'win-arm32',
 }
 
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/version.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/version.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/version.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/version.py	2024-02-03 17:39:20.063082493 -0500
@@ -1,6 +1,6 @@
 # -*- coding: utf-8 -*-
 #
-# Copyright (C) 2012-2017 The Python Software Foundation.
+# Copyright (C) 2012-2023 The Python Software Foundation.
 # See LICENSE.txt and CONTRIBUTORS.txt.
 #
 """
@@ -176,9 +176,9 @@
         return self._string
 
 
-PEP440_VERSION_RE = re.compile(r'^v?(\d+!)?(\d+(\.\d+)*)((a|b|c|rc)(\d+))?'
-                               r'(\.(post)(\d+))?(\.(dev)(\d+))?'
-                               r'(\+([a-zA-Z\d]+(\.[a-zA-Z\d]+)?))?$')
+PEP440_VERSION_RE = re.compile(r'^v?(\d+!)?(\d+(\.\d+)*)((a|alpha|b|beta|c|rc|pre|preview)(\d+)?)?'
+                               r'(\.(post|r|rev)(\d+)?)?([._-]?(dev)(\d+)?)?'
+                               r'(\+([a-zA-Z\d]+(\.[a-zA-Z\d]+)?))?$', re.I)
 
 
 def _pep_440_key(s):
@@ -202,15 +202,24 @@
     if pre == (None, None):
         pre = ()
     else:
-        pre = pre[0], int(pre[1])
+        if pre[1] is None:
+            pre = pre[0], 0
+        else:
+            pre = pre[0], int(pre[1])
     if post == (None, None):
         post = ()
     else:
-        post = post[0], int(post[1])
+        if post[1] is None:
+            post = post[0], 0
+        else:
+            post = post[0], int(post[1])
     if dev == (None, None):
         dev = ()
     else:
-        dev = dev[0], int(dev[1])
+        if dev[1] is None:
+            dev = dev[0], 0
+        else:
+            dev = dev[0], int(dev[1])
     if local is None:
         local = ()
     else:
@@ -238,7 +247,6 @@
     if not dev:
         dev = ('final',)
 
-    #print('%s -> %s' % (s, m.groups()))
     return epoch, nums, pre, post, dev, local
 
 
@@ -378,6 +386,7 @@
         pfx = '.'.join([str(i) for i in release_clause])
         return _match_prefix(version, pfx)
 
+
 _REPLACEMENTS = (
     (re.compile('[.+-]$'), ''),                     # remove trailing puncts
     (re.compile(r'^[.](\d)'), r'0.\1'),             # .N -> 0.N at start
@@ -388,7 +397,7 @@
     (re.compile('[.]{2,}'), '.'),                   # multiple runs of '.'
     (re.compile(r'\b(alfa|apha)\b'), 'alpha'),      # misspelt alpha
     (re.compile(r'\b(pre-alpha|prealpha)\b'),
-                'pre.alpha'),                       # standardise
+        'pre.alpha'),                               # standardise
     (re.compile(r'\(beta\)$'), 'beta'),             # remove parentheses
 )
 
@@ -416,7 +425,7 @@
 
     # Now look for numeric prefix, and separate it out from
     # the rest.
-    #import pdb; pdb.set_trace()
+    # import pdb; pdb.set_trace()
     m = _NUMERIC_PREFIX.match(result)
     if not m:
         prefix = '0.0.0'
@@ -434,7 +443,7 @@
         prefix = '.'.join([str(i) for i in prefix])
         suffix = suffix.strip()
     if suffix:
-        #import pdb; pdb.set_trace()
+        # import pdb; pdb.set_trace()
         # massage the suffix.
         for pat, repl in _SUFFIX_REPLACEMENTS:
             suffix = pat.sub(repl, suffix)
@@ -504,7 +513,7 @@
         rs = rs[1:]
 
     # Clean leading '0's on numbers.
-    #TODO: unintended side-effect on, e.g., "2003.05.09"
+    # TODO: unintended side-effect on, e.g., "2003.05.09"
     # PyPI stats: 77 (~2%) better
     rs = re.sub(r"\b0+(\d+)(?!\d)", r"\1", rs)
 
@@ -563,6 +572,7 @@
 #   Legacy version processing (distribute-compatible)
 #
 
+
 _VERSION_PART = re.compile(r'([a-z]+|\d+|[\.-])', re.I)
 _VERSION_REPLACE = {
     'pre': 'c',
@@ -610,7 +620,7 @@
         result = False
         for x in self._parts:
             if (isinstance(x, string_types) and x.startswith('*') and
-                x < '*final'):
+                    x < '*final'):
                 result = True
                 break
         return result
@@ -641,6 +651,7 @@
 #   Semantic versioning
 #
 
+
 _SEMVER_RE = re.compile(r'^(\d+)\.(\d+)\.(\d+)'
                         r'(-[a-z0-9]+(\.[a-z0-9-]+)*)?'
                         r'(\+[a-z0-9]+(\.[a-z0-9-]+)*)?$', re.I)
@@ -722,6 +733,7 @@
             result = self.suggester(s)
         return result
 
+
 _SCHEMES = {
     'normalized': VersionScheme(_normalized_key, NormalizedMatcher,
                                 _suggest_normalized_version),
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/wheel.py /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/wheel.py
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/distlib/wheel.py	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/distlib/wheel.py	2024-02-03 17:39:20.064082493 -0500
@@ -1,6 +1,6 @@
 # -*- coding: utf-8 -*-
 #
-# Copyright (C) 2013-2020 Vinay Sajip.
+# Copyright (C) 2013-2023 Vinay Sajip.
 # Licensed to the Python Software Foundation under a contributor agreement.
 # See LICENSE.txt and CONTRIBUTORS.txt.
 #
@@ -24,8 +24,7 @@
 from . import __version__, DistlibException
 from .compat import sysconfig, ZipFile, fsdecode, text_type, filter
 from .database import InstalledDistribution
-from .metadata import (Metadata, METADATA_FILENAME, WHEEL_METADATA_FILENAME,
-                       LEGACY_METADATA_FILENAME)
+from .metadata import Metadata, WHEEL_METADATA_FILENAME, LEGACY_METADATA_FILENAME
 from .util import (FileOperator, convert_path, CSVReader, CSVWriter, Cache,
                    cached_property, get_cache_base, read_exports, tempdir,
                    get_platform)
@@ -33,7 +32,7 @@
 
 logger = logging.getLogger(__name__)
 
-cache = None    # created when needed
+cache = None  # created when needed
 
 if hasattr(sys, 'pypy_version_info'):  # pragma: no cover
     IMP_PREFIX = 'pp'
@@ -45,7 +44,7 @@
     IMP_PREFIX = 'cp'
 
 VER_SUFFIX = sysconfig.get_config_var('py_version_nodot')
-if not VER_SUFFIX:   # pragma: no cover
+if not VER_SUFFIX:  # pragma: no cover
     VER_SUFFIX = '%s%s' % sys.version_info[:2]
 PYVER = 'py' + VER_SUFFIX
 IMPVER = IMP_PREFIX + VER_SUFFIX
@@ -56,6 +55,7 @@
 if ABI and ABI.startswith('cpython-'):
     ABI = ABI.replace('cpython-', 'cp').split('-')[0]
 else:
+
     def _derive_abi():
         parts = ['cp', VER_SUFFIX]
         if sysconfig.get_config_var('Py_DEBUG'):
@@ -73,10 +73,12 @@
                     if us == 4 or (us is None and sys.maxunicode == 0x10FFFF):
                         parts.append('u')
         return ''.join(parts)
+
     ABI = _derive_abi()
     del _derive_abi
 
-FILENAME_RE = re.compile(r'''
+FILENAME_RE = re.compile(
+    r'''
 (?P<nm>[^-]+)
 -(?P<vn>\d+[^-]*)
 (-(?P<bn>\d+[^-]*))?
@@ -86,7 +88,8 @@
 \.whl$
 ''', re.IGNORECASE | re.VERBOSE)
 
-NAME_VERSION_RE = re.compile(r'''
+NAME_VERSION_RE = re.compile(
+    r'''
 (?P<nm>[^-]+)
 -(?P<vn>\d+[^-]*)
 (-(?P<bn>\d+[^-]*))?$
@@ -109,12 +112,14 @@
     import importlib.machinery
     import importlib.util
 
+
 def _get_suffixes():
     if imp:
         return [s[0] for s in imp.get_suffixes()]
     else:
         return importlib.machinery.EXTENSION_SUFFIXES
 
+
 def _load_dynamic(name, path):
     # https://docs.python.org/3/library/importlib.html#importing-a-source-file-directly
     if imp:
@@ -126,7 +131,9 @@
         spec.loader.exec_module(module)
         return module
 
+
 class Mounter(object):
+
     def __init__(self):
         self.impure_wheels = {}
         self.libs = {}
@@ -161,6 +168,7 @@
                 result.__package__ = parts[0]
         return result
 
+
 _hook = Mounter()
 
 
@@ -227,8 +235,8 @@
         arch = '.'.join(self.arch)
         # replace - with _ as a local version separator
         version = self.version.replace('-', '_')
-        return '%s-%s%s-%s-%s-%s.whl' % (self.name, version, buildver,
-                                         pyver, abi, arch)
+        return '%s-%s%s-%s-%s-%s.whl' % (self.name, version, buildver, pyver,
+                                         abi, arch)
 
     @property
     def exists(self):
@@ -249,14 +257,14 @@
         info_dir = '%s.dist-info' % name_ver
         wrapper = codecs.getreader('utf-8')
         with ZipFile(pathname, 'r') as zf:
-            wheel_metadata = self.get_wheel_metadata(zf)
-            wv = wheel_metadata['Wheel-Version'].split('.', 1)
-            file_version = tuple([int(i) for i in wv])
+            self.get_wheel_metadata(zf)
+            # wv = wheel_metadata['Wheel-Version'].split('.', 1)
+            # file_version = tuple([int(i) for i in wv])
             # if file_version < (1, 1):
-                # fns = [WHEEL_METADATA_FILENAME, METADATA_FILENAME,
-                       # LEGACY_METADATA_FILENAME]
+            # fns = [WHEEL_METADATA_FILENAME, METADATA_FILENAME,
+            # LEGACY_METADATA_FILENAME]
             # else:
-                # fns = [WHEEL_METADATA_FILENAME, METADATA_FILENAME]
+            # fns = [WHEEL_METADATA_FILENAME, METADATA_FILENAME]
             fns = [WHEEL_METADATA_FILENAME, LEGACY_METADATA_FILENAME]
             result = None
             for fn in fns:
@@ -326,13 +334,14 @@
         try:
             hasher = getattr(hashlib, hash_kind)
         except AttributeError:
-            raise DistlibException('Unsupported hash algorithm: %r' % hash_kind)
+            raise DistlibException('Unsupported hash algorithm: %r' %
+                                   hash_kind)
         result = hasher(data).digest()
         result = base64.urlsafe_b64encode(result).rstrip(b'=').decode('ascii')
         return hash_kind, result
 
     def write_record(self, records, record_path, archive_record_path):
-        records = list(records) # make a copy, as mutated
+        records = list(records)  # make a copy, as mutated
         records.append((archive_record_path, '', ''))
         with CSVWriter(record_path) as writer:
             for row in records:
@@ -341,7 +350,7 @@
     def write_records(self, info, libdir, archive_paths):
         records = []
         distinfo, info_dir = info
-        hasher = getattr(hashlib, self.hash_kind)
+        # hasher = getattr(hashlib, self.hash_kind)
         for ap, p in archive_paths:
             with open(p, 'rb') as f:
                 data = f.read()
@@ -466,6 +475,7 @@
             if '.dist-info' in ap:
                 n += 10000
             return (n, ap)
+
         archive_paths = sorted(archive_paths, key=sorter)
 
         # Now, at last, RECORD.
@@ -512,7 +522,8 @@
         dry_run = maker.dry_run
         warner = kwargs.get('warner')
         lib_only = kwargs.get('lib_only', False)
-        bc_hashed_invalidation = kwargs.get('bytecode_hashed_invalidation', False)
+        bc_hashed_invalidation = kwargs.get('bytecode_hashed_invalidation',
+                                            False)
 
         pathname = os.path.join(self.dirname, self.filename)
         name_ver = '%s-%s' % (self.name, self.version)
@@ -553,11 +564,11 @@
             # make a new instance rather than a copy of maker's,
             # as we mutate it
             fileop = FileOperator(dry_run=dry_run)
-            fileop.record = True    # so we can rollback if needed
+            fileop.record = True  # so we can rollback if needed
 
-            bc = not sys.dont_write_bytecode    # Double negatives. Lovely!
+            bc = not sys.dont_write_bytecode  # Double negatives. Lovely!
 
-            outfiles = []   # for RECORD writing
+            outfiles = []  # for RECORD writing
 
             # for script copying/shebang processing
             workdir = tempfile.mkdtemp()
@@ -611,7 +622,8 @@
                         # So ... manually preserve permission bits as given in zinfo
                         if os.name == 'posix':
                             # just set the normal permission bits
-                            os.chmod(outfile, (zinfo.external_attr >> 16) & 0x1FF)
+                            os.chmod(outfile,
+                                     (zinfo.external_attr >> 16) & 0x1FF)
                         outfiles.append(outfile)
                         # Double check the digest of the written file
                         if not dry_run and row[1]:
@@ -624,8 +636,9 @@
                                                            '%s' % outfile)
                         if bc and outfile.endswith('.py'):
                             try:
-                                pyc = fileop.byte_compile(outfile,
-                                                          hashed_invalidation=bc_hashed_invalidation)
+                                pyc = fileop.byte_compile(
+                                    outfile,
+                                    hashed_invalidation=bc_hashed_invalidation)
                                 outfiles.append(pyc)
                             except Exception:
                                 # Don't give up if byte-compilation fails,
@@ -700,7 +713,7 @@
                                 fileop.set_executable_mode(filenames)
 
                             if gui_scripts:
-                                options = {'gui': True }
+                                options = {'gui': True}
                                 for k, v in gui_scripts.items():
                                     script = '%s = %s' % (k, v)
                                     filenames = maker.make(script, options)
@@ -710,7 +723,7 @@
                     dist = InstalledDistribution(p)
 
                     # Write SHARED
-                    paths = dict(paths)     # don't change passed in dict
+                    paths = dict(paths)  # don't change passed in dict
                     del paths['purelib']
                     del paths['platlib']
                     paths['lib'] = libdir
@@ -761,7 +774,8 @@
                             extract = True
                         else:
                             file_time = os.stat(dest).st_mtime
-                            file_time = datetime.datetime.fromtimestamp(file_time)
+                            file_time = datetime.datetime.fromtimestamp(
+                                file_time)
                             info = zf.getinfo(relpath)
                             wheel_time = datetime.datetime(*info.date_time)
                             extract = wheel_time > file_time
@@ -782,7 +796,7 @@
         """
         Determine if a wheel is asserted as mountable by its metadata.
         """
-        return True # for now - metadata details TBD
+        return True  # for now - metadata details TBD
 
     def mount(self, append=False):
         pathname = os.path.abspath(os.path.join(self.dirname, self.filename))
@@ -820,10 +834,10 @@
     def verify(self):
         pathname = os.path.join(self.dirname, self.filename)
         name_ver = '%s-%s' % (self.name, self.version)
-        data_dir = '%s.data' % name_ver
+        # data_dir = '%s.data' % name_ver
         info_dir = '%s.dist-info' % name_ver
 
-        metadata_name = posixpath.join(info_dir, LEGACY_METADATA_FILENAME)
+        # metadata_name = posixpath.join(info_dir, LEGACY_METADATA_FILENAME)
         wheel_metadata_name = posixpath.join(info_dir, 'WHEEL')
         record_name = posixpath.join(info_dir, 'RECORD')
 
@@ -832,9 +846,9 @@
         with ZipFile(pathname, 'r') as zf:
             with zf.open(wheel_metadata_name) as bwf:
                 wf = wrapper(bwf)
-                message = message_from_file(wf)
-            wv = message['Wheel-Version'].split('.', 1)
-            file_version = tuple([int(i) for i in wv])
+                message_from_file(wf)
+            # wv = message['Wheel-Version'].split('.', 1)
+            # file_version = tuple([int(i) for i in wv])
             # TODO version verification
 
             records = {}
@@ -903,25 +917,25 @@
         def update_version(version, path):
             updated = None
             try:
-                v = NormalizedVersion(version)
+                NormalizedVersion(version)
                 i = version.find('-')
                 if i < 0:
                     updated = '%s+1' % version
                 else:
                     parts = [int(s) for s in version[i + 1:].split('.')]
                     parts[-1] += 1
-                    updated = '%s+%s' % (version[:i],
-                                         '.'.join(str(i) for i in parts))
+                    updated = '%s+%s' % (version[:i], '.'.join(
+                        str(i) for i in parts))
             except UnsupportedVersionError:
-                logger.debug('Cannot update non-compliant (PEP-440) '
-                             'version %r', version)
+                logger.debug(
+                    'Cannot update non-compliant (PEP-440) '
+                    'version %r', version)
             if updated:
                 md = Metadata(path=path)
                 md.version = updated
                 legacy = path.endswith(LEGACY_METADATA_FILENAME)
                 md.write(path=path, legacy=legacy)
-                logger.debug('Version updated from %r to %r', version,
-                             updated)
+                logger.debug('Version updated from %r to %r', version, updated)
 
         pathname = os.path.join(self.dirname, self.filename)
         name_ver = '%s-%s' % (self.name, self.version)
@@ -963,7 +977,8 @@
                     os.close(fd)
                 else:
                     if not os.path.isdir(dest_dir):
-                        raise DistlibException('Not a directory: %r' % dest_dir)
+                        raise DistlibException('Not a directory: %r' %
+                                               dest_dir)
                     newpath = os.path.join(dest_dir, self.filename)
                 archive_paths = list(path_map.items())
                 distinfo = os.path.join(workdir, info_dir)
@@ -974,6 +989,7 @@
                     shutil.copyfile(newpath, pathname)
         return modified
 
+
 def _get_glibc_version():
     import platform
     ver = platform.libc_ver()
@@ -984,13 +1000,14 @@
         result = tuple(result)
     return result
 
+
 def compatible_tags():
     """
     Return (pyver, abi, arch) tuples compatible with this Python.
     """
     versions = [VER_SUFFIX]
     major = VER_SUFFIX[0]
-    for minor in range(sys.version_info[1] - 1, - 1, -1):
+    for minor in range(sys.version_info[1] - 1, -1, -1):
         versions.append(''.join([major, str(minor)]))
 
     abis = []
@@ -1023,7 +1040,7 @@
             while minor >= 0:
                 for match in matches:
                     s = '%s_%s_%s_%s' % (name, major, minor, match)
-                    if s != ARCH:   # already there
+                    if s != ARCH:  # already there
                         arches.append(s)
                 minor -= 1
 
@@ -1045,9 +1062,9 @@
                     if parts >= (2, 17):
                         result.append((''.join((IMP_PREFIX, versions[0])), abi,
                                        'manylinux2014_%s' % arch))
-                    result.append((''.join((IMP_PREFIX, versions[0])), abi,
-                                   'manylinux_%s_%s_%s' % (parts[0], parts[1],
-                                                           arch)))
+                    result.append(
+                        (''.join((IMP_PREFIX, versions[0])), abi,
+                         'manylinux_%s_%s_%s' % (parts[0], parts[1], arch)))
 
     # where no ABI / arch dependency, but IMP_PREFIX dependency
     for i, version in enumerate(versions):
@@ -1071,7 +1088,7 @@
 
 def is_compatible(wheel, tags=None):
     if not isinstance(wheel, Wheel):
-        wheel = Wheel(wheel)    # assume it's a filename
+        wheel = Wheel(wheel)  # assume it's a filename
     result = False
     if tags is None:
         tags = COMPATIBLE_TAGS
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/vendor.txt /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/vendor.txt
--- /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages/pip/_vendor/vendor.txt	2024-01-23 17:23:10.000000000 -0500
+++ /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages/pip/_vendor/vendor.txt	2024-02-03 17:39:20.061082493 -0500
@@ -1,6 +1,6 @@
 CacheControl==0.13.1  # Make sure to update the license in pyproject.toml for this.
 colorama==0.4.6
-distlib==0.3.6
+distlib==0.3.8
 distro==1.8.0
 msgpack==1.0.5
 packaging==21.3
Only in /tmp/tmp.hkmY0GQ00I/lib/python3.11/site-packages: pip-23.3.2.dist-info
Only in /tmp/tmp.Lkyh3ShbNP/lib/python3.11/site-packages: pip-24.0.dist-info
***** END DIFF
Untagged: localhost/devfileregistry:tmp
Deleted: 354b4d424f55b00eef526ef7d67917d585e5c772bad7749f147c58ece81d1cd5
Deleted: 3bfbaaf3a52b2b0e61685c9cb11e25e5c9504d0d44131a9d20032c835459322b
Deleted: ad4528fb1fb79003f0abde46afcd61334127f5b81efeb8e5e77d4bfc9ce52d86
Deleted: 3fbb78fd3ed35724caee94213c2ef17e31120d171e01c2fb0449705de60d12ea
Deleted: 0484aed031cb40ec53ddb4eb87133def198e53e4142e295183dffb0a3f75bb60
Deleted: 36ed976b7a70bf9134db3d0fece58be174da9cc3d9c25bddfad286e93eb9f540
Deleted: 472fc53603b7e93346df617348679771c1d07a50a93585746d4da36be11fbe9a
Deleted: 3e4b50f94399dd2c7596ff6abcc2b9f61b6ecc2236cb15d2925ac81bdee25cf4
Deleted: 73d517e69b1a34719e7463b6395224170d00055fda026c77b3773e3faca9d09f
Deleted: 0af5496e4db7e48125094f012b5a419b93eb2d780fa98b072dea5e86ffdeeda5
Deleted: eef27a48ab9dde082f31cf6eed58de348f41c264f3e55ab222664d5df45f62ed
Deleted: 5e8d58aa2a3566b10bd852b5759633c10d93431ae8fbc7d82fb0b363921d0848
Deleted: cc7cc464a8893454ba700b75ebe680ddbefc964d86608bb0de783bd90eff214d
Deleted: c53a8ea9a25190c4c2dd3fda4c529e4566026d225e45c9ed06e38b2160e3e08f
Deleted: 010eb9f7a322b177d81cfee8df7d42a03e8c52489efd47a44592fb76d09df99d
Deleted: 4816c80d8b5e31c7b675d8b0fd2abd560bffccdf29e5a018f05f3209170ebbf4
Deleted: a7420bffd905fc771e7c2c49ced6c3d8397a12564968a13a88ee8d22edfc45ee
Deleted: bbce6354fcf208e5b8b2c2a5e6b3a77d5bfb908ec215b859b1c90a4377eb6b45
Deleted: 1d28b2bbbbf1c08b8acd2f16bba90779353a4bc26e3cb36e2569fdb924d5acb0
Deleted: 1a971e6048785206ba3920bec65e3bf0e41c66f3e23149a666338fc49b4a7c5b
Deleted: b88b51bd25fa2669ca8629a153fd727356d118159128903fbe41311d6b01ab5c
Deleted: 01067abced624e736756bba7fcde703fb4fa992789feb4d2593105e545d8037d
Uploading: root-local.tgz
File already uploaded: resources.tgz
Source upload succeeded. Don't forget to commit the sources file
rm 'resources.tgz'
rm 'root-local.tgz'
